{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e1cd147",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API and AWS Sagemaker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85592c17",
   "metadata": {},
   "source": [
    "In this notebook, you will train and evaluate different models using the [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/) and [AWS Sagemaker](https://aws.amazon.com/sagemaker/). \n",
    "\n",
    "If you ever feel stuck, you can refer to this [tutorial](https://aws.amazon.com/blogs/machine-learning/training-and-deploying-models-using-tensorflow-2-with-the-object-detection-api-on-amazon-sagemaker/).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We are using the [Waymo Open Dataset](https://waymo.com/open/) for this project. The dataset has already been exported using the tfrecords format. The files have been created following the format described [here](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records). You can find data stored on [AWS S3](https://aws.amazon.com/s3/), AWS Object Storage. The images are saved with a resolution of 640x640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc1d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install tensorflow_io sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f55350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from framework import CustomFramework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccde6fd1",
   "metadata": {},
   "source": [
    "Save the IAM role in a variable called `role`. This would be useful when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab6b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::738138308218:role/service-role/AmazonSageMaker-ExecutionRole-20250923T072516\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae64e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train and val paths below are public S3 buckets created by Udacity for this project\n",
    "inputs = {'train': 's3://cd2688-object-detection-tf2/train/', \n",
    "          'val': 's3://cd2688-object-detection-tf2/val/'} \n",
    "\n",
    "# Insert path of a folder in your personal S3 bucket to store tensorboard logs.\n",
    "tensorboard_s3_prefix = 's3://object-detection-bucket-2/logs/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc16a825",
   "metadata": {},
   "source": [
    "## Container\n",
    "\n",
    "To train the model, you will first need to build a [docker](https://www.docker.com/) container with all the dependencies required by the TF Object Detection API. The code below does the following:\n",
    "* clone the Tensorflow models repository\n",
    "* get the exporter and training scripts from the repository\n",
    "* build the docker image and push it \n",
    "* print the container name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad5ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'docker/models'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# clone the repo and get the scripts\n",
    "git clone https://github.com/tensorflow/models.git docker/models\n",
    "\n",
    "# get model_main and exporter_main files from TF2 Object Detection GitHub repository\n",
    "cp docker/models/research/object_detection/exporter_main_v2.py source_dir \n",
    "cp docker/models/research/object_detection/model_main_tf2.py source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2dab3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#14 8.751 Collecting protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 (from apache-beam->object-detection==0.1)\n",
      "#14 8.755   Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "#14 8.772 Collecting pydot<2,>=1.2.0 (from apache-beam->object-detection==0.1)\n",
      "#14 8.778   Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "#14 8.823 Collecting redis<6,>=5.0.0 (from apache-beam->object-detection==0.1)\n",
      "#14 8.827   Downloading redis-5.3.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "#14 8.883 Collecting requests<3.0.0,>=2.24.0 (from apache-beam->object-detection==0.1)\n",
      "#14 8.892   Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "#14 8.899 Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
      "#14 8.973 Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
      "#14 9.001   Downloading zstandard-0.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "#14 9.132 Collecting pyarrow<17.0.0,>=3.0.0 (from apache-beam->object-detection==0.1)\n",
      "#14 9.137   Downloading pyarrow-16.1.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "#14 9.155 Collecting pyarrow-hotfix<1 (from apache-beam->object-detection==0.1)\n",
      "#14 9.159   Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "#14 9.181 Collecting cycler>=0.10.0 (from lvis->object-detection==0.1)\n",
      "#14 9.185   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "#14 9.261 Collecting kiwisolver>=1.1.0 (from lvis->object-detection==0.1)\n",
      "#14 9.265   Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.3 kB)\n",
      "#14 9.353 Collecting opencv-python>=4.1.0.25 (from lvis->object-detection==0.1)\n",
      "#14 9.387   Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "#14 9.464 Collecting contourpy>=1.0.1 (from matplotlib->object-detection==0.1)\n",
      "#14 9.476   Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "#14 9.629 Collecting fonttools>=4.22.0 (from matplotlib->object-detection==0.1)\n",
      "#14 9.636   Downloading fonttools-4.57.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "#14 9.694 Collecting importlib-resources>=3.2.0 (from matplotlib->object-detection==0.1)\n",
      "#14 9.698   Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "#14 9.798 Collecting tensorflow-io-gcs-filesystem==0.34.0 (from tensorflow_io->object-detection==0.1)\n",
      "#14 9.825   Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "#14 9.853 Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.21.0)\n",
      "#14 9.865 Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 9.873   Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "#14 9.932 Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 9.936   Downloading google_api_core-2.25.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "#14 9.956 Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 9.971   Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "#14 9.989 Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
      "#14 9.997   Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "#14 10.01   Preparing metadata (setup.py): started\n",
      "#14 10.16   Preparing metadata (setup.py): finished with status 'done'\n",
      "#14 10.19 Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib->object-detection==0.1) (3.15.0)\n",
      "#14 10.21 Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1)\n",
      "#14 10.21   Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "#14 10.25 Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1)\n",
      "#14 10.25   Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "#14 10.27 Collecting pkgutil-resolve-name>=1.3.10 (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1)\n",
      "#14 10.27   Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl.metadata (624 bytes)\n",
      "#14 10.30 Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1)\n",
      "#14 10.33   Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "#14 10.59 Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1)\n",
      "#14 10.59   Downloading rpds_py-0.20.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "#14 10.62 Collecting bleach (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 10.67   Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "#14 10.68 Requirement already satisfied: certifi>=14.05.14 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2019.11.28)\n",
      "#14 10.75 Collecting charset-normalizer (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 10.76   Downloading charset_normalizer-3.4.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
      "#14 10.77 Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8)\n",
      "#14 10.78 Collecting python-slugify (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 10.79   Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "#14 10.79 Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (68.0.0)\n",
      "#14 10.80 Collecting text-unidecode (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 10.81   Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "#14 10.85 Collecting tqdm (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 10.85   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "#14 10.86 Requirement already satisfied: urllib3>=1.15.1 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.25.8)\n",
      "#14 10.86 Requirement already satisfied: webencodings in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
      "#14 11.03 Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
      "#14 11.03   Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "#14 11.07 Collecting PyJWT>=2.9.0 (from redis<6,>=5.0.0->apache-beam->object-detection==0.1)\n",
      "#14 11.07   Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "#14 11.10 Collecting async-timeout>=4.0.3 (from redis<6,>=5.0.0->apache-beam->object-detection==0.1)\n",
      "#14 11.10   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "#14 11.13 Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "#14 11.13 Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\n",
      "#14 11.13 Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "#14 11.13 Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "#14 11.13 Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n",
      "#14 11.13 Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.0)\n",
      "#14 11.13 Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "#14 11.23 Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.13.0)\n",
      "#14 11.23 Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.13.0)\n",
      "#14 11.23 Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n",
      "#14 11.23 Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.15.0)\n",
      "#14 11.32 Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.6.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 11.37   Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "#14 11.40 Collecting dm-tree~=0.1.1 (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 11.44   Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "#14 11.47 Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "#14 11.47 Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n",
      "#14 11.47 Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
      "#14 11.56 Collecting scikit-learn>=0.21.3 (from seqeval->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 11.57   Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "#14 11.62 Collecting array-record (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 11.64   Downloading array_record-0.4.0-py38-none-any.whl.metadata (502 bytes)\n",
      "#14 11.67 Collecting click (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 11.75   Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "#14 11.77 Collecting etils>=0.9.0 (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 11.81   Downloading etils-1.3.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "#14 11.84 Collecting promise (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 11.86   Downloading promise-2.3.tar.gz (19 kB)\n",
      "#14 11.87   Preparing metadata (setup.py): started\n",
      "#14 12.02   Preparing metadata (setup.py): finished with status 'done'\n",
      "#14 12.24 Collecting tensorflow-metadata (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 12.25   Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "#14 12.37 Collecting toml (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 12.38   Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "#14 12.39 Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.40.0)\n",
      "#14 12.44 Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 12.45   Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "#14 12.58 Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.1)\n",
      "#14 12.66 Collecting joblib>=1.1.1 (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 12.68   Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "#14 12.70 Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 12.71   Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "#14 12.73 Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
      "#14 12.73 Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.3)\n",
      "#14 12.75 Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\n",
      "#14 12.75 Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.6)\n",
      "#14 12.85 INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "#14 12.85 Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.6.0->tf-models-official>=2.5.1->object-detection==0.1)\n",
      "#14 12.87   Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "#14 13.02 Collecting protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 (from apache-beam->object-detection==0.1)\n",
      "#14 13.04   Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (679 bytes)\n",
      "#14 13.06 Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
      "#14 13.18 Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (6.7.0)\n",
      "#14 13.18 Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.3)\n",
      "#14 13.20 Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
      "#14 13.23 Downloading Pillow-9.5.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "#14 13.29    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 56.5 MB/s eta 0:00:00\n",
      "#14 13.30 Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "#14 13.31 Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
      "#14 13.32 Downloading tf_models_official-2.13.2-py2.py3-none-any.whl (2.6 MB)\n",
      "#14 13.35    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 74.6 MB/s eta 0:00:00\n",
      "#14 13.36 Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "#14 13.44    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 161.1 MB/s eta 0:00:00\n",
      "#14 13.44 Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "#14 13.71    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 129.6 MB/s eta 0:00:00\n",
      "#14 13.72 Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "#14 13.73 Downloading apache_beam-2.60.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
      "#14 13.95    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.2/16.2 MB 72.8 MB/s eta 0:00:00\n",
      "#14 13.96 Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "#14 13.97 Downloading cython-3.1.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "#14 13.99    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 135.0 MB/s eta 0:00:00\n",
      "#14 14.00 Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "#14 14.01 Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "#14 14.09    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 116.1 MB/s eta 0:00:00\n",
      "#14 14.09 Downloading pycocotools-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (439 kB)\n",
      "#14 14.11 Downloading tensorflow_io-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.8 MB)\n",
      "#14 14.57    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.8/28.8 MB 62.2 MB/s eta 0:00:00\n",
      "#14 14.58 Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "#14 14.62    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 53.0 MB/s eta 0:00:00\n",
      "#14 14.63 Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "#14 14.64 Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "#14 14.65 Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "#14 14.66 Downloading fastavro-1.9.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "#14 14.69    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 97.8 MB/s eta 0:00:00\n",
      "#14 14.70 Downloading fasteners-0.20-py3-none-any.whl (18 kB)\n",
      "#14 14.71 Downloading fonttools-4.57.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "#14 14.74    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 164.2 MB/s eta 0:00:00\n",
      "#14 14.74 Downloading google_api_python_client-2.184.0-py3-none-any.whl (14.3 MB)\n",
      "#14 14.83    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.3/14.3 MB 160.1 MB/s eta 0:00:00\n",
      "#14 14.84 Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "#14 14.85 Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "#14 14.86 Downloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
      "#14 14.87 Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "#14 14.88 Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "#14 14.88 Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "#14 14.89    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 113.1 MB/s eta 0:00:00\n",
      "#14 14.90 Downloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
      "#14 14.93 Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "#14 15.76    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 MB 80.3 MB/s eta 0:00:00\n",
      "#14 15.77 Downloading orjson-3.10.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "#14 15.78 Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "#14 15.78 Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
      "#14 15.79 Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "#14 15.80 Downloading pyarrow-16.1.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.9 MB)\n",
      "#14 16.46    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 MB 61.9 MB/s eta 0:00:00\n",
      "#14 16.46 Downloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
      "#14 16.47 Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "#14 16.50 Downloading pymongo-4.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (930 kB)\n",
      "#14 16.53    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 930.2/930.2 kB 22.1 MB/s eta 0:00:00\n",
      "#14 16.55 Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "#14 16.56 Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "#14 16.58 Downloading PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
      "#14 16.59    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 806.0/806.0 kB 78.8 MB/s eta 0:00:00\n",
      "#14 16.59 Downloading redis-5.3.1-py3-none-any.whl (272 kB)\n",
      "#14 16.60 Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "#14 16.62    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.1/785.1 kB 58.4 MB/s eta 0:00:00\n",
      "#14 16.62 Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "#14 16.64 Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "#14 16.65 Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "#14 16.67 Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
      "#14 16.69 Downloading tensorflow_text-2.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "#14 17.45    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 8.2 MB/s eta 0:00:00\n",
      "#14 17.46 Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "#14 17.47 Downloading zstandard-0.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "#14 17.54    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 84.8 MB/s eta 0:00:00\n",
      "#14 17.54 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "#14 17.55 Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "#14 17.56 Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "#14 17.56 Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "#14 17.57 Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "#14 17.92    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 MB 155.1 MB/s eta 0:00:00\n",
      "#14 17.93 Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "#14 17.95 Downloading sentencepiece-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "#14 17.99    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 25.8 MB/s eta 0:00:00\n",
      "#14 18.01 Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
      "#14 18.12    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 48.4 MB/s eta 0:00:00\n",
      "#14 18.13 Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "#14 18.14 Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "#14 18.15 Downloading charset_normalizer-3.4.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (147 kB)\n",
      "#14 18.16 Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "#14 18.18 Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "#14 18.20 Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
      "#14 18.22 Downloading google_api_core-2.25.2-py3-none-any.whl (162 kB)\n",
      "#14 18.23 Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "#14 18.24 Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "#14 18.24 Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "#14 18.26 Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "#14 18.27 Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "#14 18.29 Downloading rpds_py-0.20.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (360 kB)\n",
      "#14 18.32 Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "#14 18.47    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.1/11.1 MB 69.8 MB/s eta 0:00:00\n",
      "#14 18.48 Downloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "#14 18.51    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 48.5 MB/s eta 0:00:00\n",
      "#14 18.52 Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "#14 18.55 Downloading array_record-0.4.0-py38-none-any.whl (3.0 MB)\n",
      "#14 18.60    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 50.8 MB/s eta 0:00:00\n",
      "#14 18.61 Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "#14 18.62 Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "#14 18.63 Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "#14 18.64 Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "#14 18.65 Downloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "#14 18.65 Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "#14 18.66    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 109.6 MB/s eta 0:00:00\n",
      "#14 18.67 Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "#14 18.67 Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "#14 18.69 Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "#14 18.71 Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "#14 18.73 Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "#14 19.10 Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, docopt, promise\n",
      "#14 19.11   Building wheel for object-detection (setup.py): started\n",
      "#14 19.73   Building wheel for object-detection (setup.py): finished with status 'done'\n",
      "#14 19.74   Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1466904 sha256=967784ae69bb6ffe3a86239c648ec0072dbac4fd0573bd8d6d50ce49f9057446\n",
      "#14 19.74   Stored in directory: /tmp/pip-ephem-wheel-cache-hymbdo64/wheels/28/d2/ce/f2754826bc8f50adf45d76a4c3cffa1a58dd936429295e0ddd\n",
      "#14 19.74   Building wheel for avro-python3 (setup.py): started\n",
      "#14 20.04   Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
      "#14 20.05   Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43994 sha256=fbb86dfc79d5ce704f7bafc302780dedc5b1db04bb354f50dcf22b5261084ac2\n",
      "#14 20.05   Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
      "#14 20.05   Building wheel for crcmod (setup.py): started\n",
      "#14 20.45   Building wheel for crcmod (setup.py): finished with status 'done'\n",
      "#14 20.45   Created wheel for crcmod: filename=crcmod-1.7-cp38-cp38-linux_x86_64.whl size=36023 sha256=945ccac981f83874b36efda6b69d3726b236f8f72b717d5b6baa0c582c7885b8\n",
      "#14 20.45   Stored in directory: /root/.cache/pip/wheels/ca/5a/02/f3acf982a026f3319fb3e798a8dca2d48fafee7761788562e9\n",
      "#14 20.45   Building wheel for dill (setup.py): started\n",
      "#14 20.68   Building wheel for dill (setup.py): finished with status 'done'\n",
      "#14 20.68   Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=82b8af8b5754cff6344f658fdb1d877f40b19022a98123de39ab67cd6e1e26ba\n",
      "#14 20.68   Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
      "#14 20.68   Building wheel for hdfs (setup.py): started\n",
      "#14 20.89   Building wheel for hdfs (setup.py): finished with status 'done'\n",
      "#14 20.89   Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34328 sha256=872e4417c6f69943a27a6f28d5e9ca75df68547bfb616e48b5b990865d0a7493\n",
      "#14 20.89   Stored in directory: /root/.cache/pip/wheels/68/dd/29/c1a590238f9ebbe4f7ee9b3583f5185d0b9577e23f05c990eb\n",
      "#14 20.90   Building wheel for seqeval (setup.py): started\n",
      "#14 21.22   Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "#14 21.22   Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=b4b50cb6261e7ec6a55dc6f1ed08298885e0d9754577170a0eb5a6a8bd7e5eb0\n",
      "#14 21.22   Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "#14 21.22   Building wheel for docopt (setup.py): started\n",
      "#14 21.42   Building wheel for docopt (setup.py): finished with status 'done'\n",
      "#14 21.42   Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=c54b6e8723adf2d66c2e2163a7daabaabd09df9c3061a2711cec7b09fff6a183\n",
      "#14 21.42   Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "#14 21.43   Building wheel for promise (setup.py): started\n",
      "#14 21.64   Building wheel for promise (setup.py): finished with status 'done'\n",
      "#14 21.64   Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=07db731e1d75365a9b7a34c15ab982a27d31cfea7a2ee819f9b3f4e341fae0ba\n",
      "#14 21.64   Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "#14 21.64 Successfully built object-detection avro-python3 crcmod dill hdfs seqeval docopt promise\n",
      "#14 22.05 Installing collected packages: text-unidecode, sentencepiece, pytz, py-cpuinfo, gin-config, docopt, dm-tree, crcmod, zstandard, uritemplate, tzdata, tqdm, toml, threadpoolctl, tf-slim, tf-keras, tensorflow-model-optimization, tensorflow-io-gcs-filesystem, tabulate, scipy, rpds-py, regex, pyyaml, python-slugify, python-dateutil, pyparsing, PyJWT, pyarrow-hotfix, pyarrow, psutil, protobuf, promise, portalocker, pkgutil-resolve-name, pillow, orjson, opencv-python-headless, opencv-python, objsize, kiwisolver, jsonpickle, joblib, importlib-resources, immutabledict, fonttools, fasteners, fastavro, etils, dnspython, dill, Cython, cycler, contourpy, contextlib2, colorama, cloudpickle, click, charset-normalizer, bleach, avro-python3, attrs, async-timeout, tensorflow_io, tensorflow-hub, scikit-learn, sacrebleu, requests, referencing, redis, pymongo, pydot, proto-plus, pandas, matplotlib, httplib2, googleapis-common-protos, tensorflow-metadata, seqeval, pycocotools, oauth2client, lvis, kaggle, jsonschema-specifications, hdfs, google-auth-httplib2, google-api-core, jsonschema, google-api-python-client, array-record, tensorflow-datasets, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
      "#14 23.58   Attempting uninstall: tensorflow-io-gcs-filesystem\n",
      "#14 23.58     Found existing installation: tensorflow-io-gcs-filesystem 0.32.0\n",
      "#14 23.58     Uninstalling tensorflow-io-gcs-filesystem-0.32.0:\n",
      "#14 23.59       Successfully uninstalled tensorflow-io-gcs-filesystem-0.32.0\n",
      "#14 27.46   Attempting uninstall: protobuf\n",
      "#14 27.46     Found existing installation: protobuf 3.20.1\n",
      "#14 27.46     Uninstalling protobuf-3.20.1:\n",
      "#14 27.68       Successfully uninstalled protobuf-3.20.1\n",
      "#14 27.80   Attempting uninstall: pillow\n",
      "#14 27.80     Found existing installation: Pillow 7.0.0\n",
      "#14 27.80     Uninstalling Pillow-7.0.0:\n",
      "#14 27.84       Successfully uninstalled Pillow-7.0.0\n",
      "#14 33.65   Attempting uninstall: requests\n",
      "#14 33.66     Found existing installation: requests 2.22.0\n",
      "#14 33.66     Uninstalling requests-2.22.0:\n",
      "#14 33.67       Successfully uninstalled requests-2.22.0\n",
      "#14 44.56 Successfully installed Cython-3.1.4 PyJWT-2.9.0 apache-beam-2.60.0 array-record-0.4.0 async-timeout-5.0.1 attrs-25.3.0 avro-python3-1.10.2 bleach-6.1.0 charset-normalizer-3.4.3 click-8.1.8 cloudpickle-2.2.1 colorama-0.4.6 contextlib2-21.6.0 contourpy-1.1.1 crcmod-1.7 cycler-0.12.1 dill-0.3.1.1 dm-tree-0.1.8 dnspython-2.6.1 docopt-0.6.2 etils-1.3.0 fastavro-1.9.7 fasteners-0.20 fonttools-4.57.0 gin-config-0.5.0 google-api-core-2.25.2 google-api-python-client-2.184.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.70.0 hdfs-2.7.3 httplib2-0.22.0 immutabledict-4.2.1 importlib-resources-6.4.5 joblib-1.4.2 jsonpickle-3.4.2 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 kaggle-1.7.4.5 kiwisolver-1.4.7 lvis-0.5.3 matplotlib-3.7.5 oauth2client-4.1.3 object-detection-0.1 objsize-0.7.1 opencv-python-4.12.0.88 opencv-python-headless-4.12.0.88 orjson-3.10.15 pandas-2.0.3 pillow-9.5.0 pkgutil-resolve-name-1.3.10 portalocker-3.0.0 promise-2.3 proto-plus-1.26.1 protobuf-3.20.3 psutil-7.1.0 py-cpuinfo-9.0.0 pyarrow-16.1.0 pyarrow-hotfix-0.7 pycocotools-2.0.7 pydot-1.4.2 pymongo-4.10.1 pyparsing-2.4.7 python-dateutil-2.9.0.post0 python-slugify-8.0.4 pytz-2025.2 pyyaml-6.0.3 redis-5.3.1 referencing-0.35.1 regex-2024.11.6 requests-2.32.4 rpds-py-0.20.1 sacrebleu-2.2.0 scikit-learn-1.3.2 scipy-1.10.1 sentencepiece-0.2.0 seqeval-1.2.2 tabulate-0.9.0 tensorflow-datasets-4.9.2 tensorflow-hub-0.16.1 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-metadata-1.14.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.13.0 tensorflow_io-0.34.0 text-unidecode-1.3 tf-keras-2.15.0 tf-models-official-2.13.2 tf-slim-1.1.0 threadpoolctl-3.5.0 toml-0.10.2 tqdm-4.67.1 tzdata-2025.2 uritemplate-4.1.1 zstandard-0.23.0\n",
      "#14 44.56 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#14 DONE 52.7s\n",
      "\n",
      "#15 [11/12] RUN pip3 install sagemaker-training\n",
      "#15 0.552 Collecting sagemaker-training\n",
      "#15 0.577   Downloading sagemaker_training-5.1.1.tar.gz (59 kB)\n",
      "#15 0.598   Preparing metadata (setup.py): started\n",
      "#15 0.834   Preparing metadata (setup.py): finished with status 'done'\n",
      "#15 0.840 Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sagemaker-training) (1.24.3)\n",
      "#15 1.166 Collecting boto3 (from sagemaker-training)\n",
      "#15 1.178   Downloading boto3-1.37.38-py3-none-any.whl.metadata (6.7 kB)\n",
      "#15 1.185 Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sagemaker-training) (1.14.0)\n",
      "#15 1.186 Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from sagemaker-training) (25.0.1)\n",
      "#15 1.197 Collecting retrying>=1.3.3 (from sagemaker-training)\n",
      "#15 1.201   Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "#15 1.311 Collecting gevent (from sagemaker-training)\n",
      "#15 1.330   Downloading gevent-24.2.1-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "#15 1.356 Collecting inotify_simple==1.2.1 (from sagemaker-training)\n",
      "#15 1.361   Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "#15 1.369   Preparing metadata (setup.py): started\n",
      "#15 1.536   Preparing metadata (setup.py): finished with status 'done'\n",
      "#15 1.538 Requirement already satisfied: werkzeug>=0.15.5 in /usr/local/lib/python3.8/dist-packages (from sagemaker-training) (2.3.6)\n",
      "#15 1.568 Collecting paramiko>=2.4.2 (from sagemaker-training)\n",
      "#15 1.575   Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "#15 1.584 Requirement already satisfied: psutil>=5.6.7 in /usr/local/lib/python3.8/dist-packages (from sagemaker-training) (7.1.0)\n",
      "#15 1.759 Collecting protobuf>=5.28.1 (from sagemaker-training)\n",
      "#15 1.763   Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "#15 1.769 Requirement already satisfied: scipy>=1.2.2 in /usr/local/lib/python3.8/dist-packages (from sagemaker-training) (1.10.1)\n",
      "#15 2.248 Collecting botocore>=1.31.57 (from sagemaker-training)\n",
      "#15 2.253   Downloading botocore-1.37.38-py3-none-any.whl.metadata (5.7 kB)\n",
      "#15 2.448 Collecting jmespath<2.0.0,>=0.7.1 (from boto3->sagemaker-training)\n",
      "#15 2.452   Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "#15 2.476 Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->sagemaker-training)\n",
      "#15 2.479   Downloading s3transfer-0.11.5-py3-none-any.whl.metadata (1.7 kB)\n",
      "#15 2.486 Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore>=1.31.57->sagemaker-training) (2.9.0.post0)\n",
      "#15 2.487 Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3/dist-packages (from botocore>=1.31.57->sagemaker-training) (1.25.8)\n",
      "#15 2.531 Collecting bcrypt>=3.2 (from paramiko>=2.4.2->sagemaker-training)\n",
      "#15 2.538   Downloading bcrypt-5.0.0-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "#15 2.725 Collecting cryptography>=3.3 (from paramiko>=2.4.2->sagemaker-training)\n",
      "#15 2.729   Downloading cryptography-46.0.2-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "#15 2.760 Collecting pynacl>=1.5 (from paramiko>=2.4.2->sagemaker-training)\n",
      "#15 2.767   Downloading pynacl-1.6.0-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
      "#15 2.787 Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=0.15.5->sagemaker-training) (2.1.3)\n",
      "#15 2.799 Collecting zope.event (from gevent->sagemaker-training)\n",
      "#15 2.806   Downloading zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "#15 2.918 Collecting zope.interface (from gevent->sagemaker-training)\n",
      "#15 2.923   Downloading zope.interface-7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "#15 3.090 Collecting greenlet>=2.0.0 (from gevent->sagemaker-training)\n",
      "#15 3.097   Downloading greenlet-3.1.1-cp38-cp38-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "#15 3.106 Requirement already satisfied: cffi>=1.14 in /usr/lib/python3/dist-packages (from cryptography>=3.3->paramiko>=2.4.2->sagemaker-training) (1.14.0)\n",
      "#15 3.124 Collecting typing-extensions>=4.13.2 (from cryptography>=3.3->paramiko>=2.4.2->sagemaker-training)\n",
      "#15 3.128   Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "#15 3.243 Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from zope.event->gevent->sagemaker-training) (68.0.0)\n",
      "#15 3.258 Downloading boto3-1.37.38-py3-none-any.whl (139 kB)\n",
      "#15 3.269 Downloading botocore-1.37.38-py3-none-any.whl (13.5 MB)\n",
      "#15 3.345    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 182.4 MB/s eta 0:00:00\n",
      "#15 3.348 Downloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
      "#15 3.367 Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "#15 3.375 Downloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
      "#15 3.383 Downloading gevent-24.2.1-cp38-cp38-manylinux_2_28_x86_64.whl (6.7 MB)\n",
      "#15 3.444    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.7/6.7 MB 110.1 MB/s eta 0:00:00\n",
      "#15 3.449 Downloading bcrypt-5.0.0-cp38-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "#15 3.483 Downloading cryptography-46.0.2-cp38-abi3-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "#15 3.519    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 130.4 MB/s eta 0:00:00\n",
      "#15 3.523 Downloading greenlet-3.1.1-cp38-cp38-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (605 kB)\n",
      "#15 3.534    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 606.0/606.0 kB 49.9 MB/s eta 0:00:00\n",
      "#15 3.540 Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "#15 3.549 Downloading pynacl-1.6.0-cp38-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "#15 3.560    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 134.6 MB/s eta 0:00:00\n",
      "#15 3.564 Downloading s3transfer-0.11.5-py3-none-any.whl (84 kB)\n",
      "#15 3.571 Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "#15 3.582 Downloading zope.interface-7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (257 kB)\n",
      "#15 3.590 Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "#15 3.638 Building wheels for collected packages: sagemaker-training, inotify_simple\n",
      "#15 3.639   Building wheel for sagemaker-training (setup.py): started\n",
      "#15 4.296   Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "#15 4.297   Created wheel for sagemaker-training: filename=sagemaker_training-5.1.1-cp38-cp38-linux_x86_64.whl size=92746 sha256=191a943b90ba7545ee759186916dcd03d991709f53dcf1b5af395c9b213958a9\n",
      "#15 4.297   Stored in directory: /root/.cache/pip/wheels/77/ad/06/8188c6d965cddc058810e64fe7ce6449a0e7da648186f85003\n",
      "#15 4.300   Building wheel for inotify_simple (setup.py): started\n",
      "#15 4.580   Building wheel for inotify_simple (setup.py): finished with status 'done'\n",
      "#15 4.580   Created wheel for inotify_simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8201 sha256=027b293e793aee1106120815d4e883985900b794bd2349e497a5fdd5b6f6f08c\n",
      "#15 4.581   Stored in directory: /root/.cache/pip/wheels/8b/2d/c2/46bac8503a2469925f6f463615984b3d1fe472e729363a28d3\n",
      "#15 4.583 Successfully built sagemaker-training inotify_simple\n",
      "#15 4.915 Installing collected packages: inotify_simple, zope.interface, zope.event, typing-extensions, retrying, pynacl, protobuf, jmespath, greenlet, bcrypt, gevent, cryptography, botocore, s3transfer, paramiko, boto3, sagemaker-training\n",
      "#15 5.048   Attempting uninstall: typing-extensions\n",
      "#15 5.050     Found existing installation: typing_extensions 4.5.0\n",
      "#15 5.051     Uninstalling typing_extensions-4.5.0:\n",
      "#15 5.364       Successfully uninstalled typing_extensions-4.5.0\n",
      "#15 5.450   Attempting uninstall: protobuf\n",
      "#15 5.451     Found existing installation: protobuf 3.20.3\n",
      "#15 5.457     Uninstalling protobuf-3.20.3:\n",
      "#15 5.749       Successfully uninstalled protobuf-3.20.3\n",
      "#15 7.163 ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "#15 7.163 apache-beam 2.60.0 requires protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3, but you have protobuf 5.29.5 which is incompatible.\n",
      "#15 7.163 tensorflow 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.5 which is incompatible.\n",
      "#15 7.163 tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.13.2 which is incompatible.\n",
      "#15 7.163 tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 5.29.5 which is incompatible.\n",
      "#15 7.163 Successfully installed bcrypt-5.0.0 boto3-1.37.38 botocore-1.37.38 cryptography-46.0.2 gevent-24.2.1 greenlet-3.1.1 inotify_simple-1.2.1 jmespath-1.0.1 paramiko-3.5.1 protobuf-5.29.5 pynacl-1.6.0 retrying-1.4.2 s3transfer-0.11.5 sagemaker-training-5.1.1 typing-extensions-4.13.2 zope.event-5.0 zope.interface-7.2\n",
      "#15 7.163 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#15 DONE 7.6s\n",
      "\n",
      "#16 [12/12] RUN pip install \"opencv-python-headless<4.3\"\n",
      "#16 0.613 Collecting opencv-python-headless<4.3\n",
      "#16 0.627   Downloading opencv_python_headless-4.2.0.34-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "#16 0.634 Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python-headless<4.3) (1.24.3)\n",
      "#16 0.641 Downloading opencv_python_headless-4.2.0.34-cp38-cp38-manylinux1_x86_64.whl (21.6 MB)\n",
      "#16 1.577    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.6/21.6 MB 23.0 MB/s eta 0:00:00\n",
      "#16 1.915 Installing collected packages: opencv-python-headless\n",
      "#16 1.916   Attempting uninstall: opencv-python-headless\n",
      "#16 1.917     Found existing installation: opencv-python-headless 4.12.0.88\n",
      "#16 1.924     Uninstalling opencv-python-headless-4.12.0.88:\n",
      "#16 2.149       Successfully uninstalled opencv-python-headless-4.12.0.88\n",
      "#16 2.517 Successfully installed opencv-python-headless-4.2.0.34\n",
      "#16 2.517 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#16 DONE 2.7s\n",
      "\n",
      "#17 exporting to image\n",
      "#17 exporting layers\n",
      "#17 exporting layers 4.5s done\n",
      "#17 writing image sha256:60b8664ca49260656e1936b24d1f0307ee6fd478fbc3b64242bb666a71814283 done\n",
      "#17 naming to docker.io/library/tf2-object-detection done\n",
      "#17 DONE 4.5s\n",
      "Pushing image to ECR 738138308218.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20251003012007\n",
      "The push refers to repository [738138308218.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection]\n",
      "c05bfab74668: Preparing\n",
      "791cf176ddcc: Preparing\n",
      "41adfa83c890: Preparing\n",
      "82b5227fc274: Preparing\n",
      "9dd622eefc64: Preparing\n",
      "7c921cca253a: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "7b8d4097c480: Preparing\n",
      "0a2820ba0cb0: Preparing\n",
      "c40472a17873: Preparing\n",
      "62020b7c1652: Preparing\n",
      "a073a40e4dcd: Preparing\n",
      "2ec1b5695a98: Preparing\n",
      "0b37f0d116f4: Preparing\n",
      "da5d2813a979: Preparing\n",
      "0eaa6e868aa5: Preparing\n",
      "1ca9136c7d36: Preparing\n",
      "dca2891e0e76: Preparing\n",
      "eaa2ed848ac5: Preparing\n",
      "ff3418b47754: Preparing\n",
      "d3dd91e05b94: Preparing\n",
      "d49fe103257c: Preparing\n",
      "e67ab25399cb: Preparing\n",
      "9a09b667a965: Preparing\n",
      "93b76ad9c95e: Preparing\n",
      "a2fdb4e1ecd1: Preparing\n",
      "0ceb5c845fcf: Preparing\n",
      "6426a7216f78: Preparing\n",
      "ec66d8cea54a: Preparing\n",
      "7c921cca253a: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "7b8d4097c480: Waiting\n",
      "0a2820ba0cb0: Waiting\n",
      "c40472a17873: Waiting\n",
      "62020b7c1652: Waiting\n",
      "a073a40e4dcd: Waiting\n",
      "2ec1b5695a98: Waiting\n",
      "0b37f0d116f4: Waiting\n",
      "da5d2813a979: Waiting\n",
      "0eaa6e868aa5: Waiting\n",
      "1ca9136c7d36: Waiting\n",
      "dca2891e0e76: Waiting\n",
      "eaa2ed848ac5: Waiting\n",
      "ff3418b47754: Waiting\n",
      "0ceb5c845fcf: Waiting\n",
      "d3dd91e05b94: Waiting\n",
      "d49fe103257c: Waiting\n",
      "e67ab25399cb: Waiting\n",
      "9a09b667a965: Waiting\n",
      "6426a7216f78: Waiting\n",
      "ec66d8cea54a: Waiting\n",
      "93b76ad9c95e: Waiting\n",
      "a2fdb4e1ecd1: Waiting\n",
      "9dd622eefc64: Pushed\n",
      "82b5227fc274: Pushed\n",
      "7c921cca253a: Pushed\n",
      "5f70bf18a086: Pushed\n",
      "7b8d4097c480: Pushed\n",
      "c40472a17873: Pushed\n",
      "0a2820ba0cb0: Pushed\n",
      "a073a40e4dcd: Layer already exists\n",
      "2ec1b5695a98: Layer already exists\n",
      "0b37f0d116f4: Layer already exists\n",
      "da5d2813a979: Layer already exists\n",
      "c05bfab74668: Pushed\n",
      "1ca9136c7d36: Layer already exists\n",
      "0eaa6e868aa5: Layer already exists\n",
      "eaa2ed848ac5: Layer already exists\n",
      "dca2891e0e76: Layer already exists\n",
      "ff3418b47754: Layer already exists\n",
      "d3dd91e05b94: Layer already exists\n",
      "d49fe103257c: Layer already exists\n",
      "e67ab25399cb: Layer already exists\n",
      "93b76ad9c95e: Layer already exists\n",
      "9a09b667a965: Layer already exists\n",
      "a2fdb4e1ecd1: Layer already exists\n",
      "0ceb5c845fcf: Layer already exists\n",
      "6426a7216f78: Layer already exists\n",
      "791cf176ddcc: Pushed\n",
      "ec66d8cea54a: Pushed\n",
      "62020b7c1652: Pushed\n",
      "41adfa83c890: Pushed\n",
      "20251003012007: digest: sha256:c048edc58cc2986ba0a7355c9876f7025a171d9711e9d65dd017642245f6d4d3 size: 6398\n",
      "Saving ECR image URI into ecr_image_fullname.txt\n"
     ]
    }
   ],
   "source": [
    "# build and push the docker image. This code can be commented out after being run once.\n",
    "# This will take around 10 mins.\n",
    "image_name = 'tf2-object-detection'\n",
    "!sh ./docker/build_and_push.sh $image_name 2>&1 | tail -n 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e62b3562",
   "metadata": {},
   "source": [
    "To verify that the image was correctly pushed to the [Elastic Container Registry](https://aws.amazon.com/ecr/), you can look at it in the AWS webapp. For example, below you can see that three different images have been pushed to ECR. You should only see one, called `tf2-object-detection`.\n",
    "![ECR Example](../data/example_ecr.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0310b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738138308218.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20251003012007\n"
     ]
    }
   ],
   "source": [
    "# display the container name\n",
    "with open (os.path.join('docker', 'ecr_image_fullname.txt'), 'r') as f:\n",
    "    container = f.readlines()[0][:-1]\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13b2a754",
   "metadata": {},
   "source": [
    "## Pre-trained model from model zoo\n",
    "\n",
    "As often, we are not training from scratch and we will be using a pretrained model from the TF Object Detection model zoo. You can find pretrained checkpoints [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Because your time is limited for this project, we recommend to only experiment with the following models:\n",
    "* SSD MobileNet V2 FPNLite 640x640\t\n",
    "* SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\t\n",
    "* Faster R-CNN ResNet50 V1 640x640\t\n",
    "* EfficientDet D1 640x640\t\n",
    "* Faster R-CNN ResNet152 V1 640x640\t\n",
    "\n",
    "In the code below, the EfficientDet D1 model is downloaded and extracted. This code should be adjusted if you were to experiment with other architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c4b1d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/tmp/checkpoint’: File exists\n",
      "mkdir: cannot create directory ‘source_dir/checkpoint’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214250K .......... .......... .......... .......... .......... 89%  222M 0s\n",
      "214300K .......... .......... .......... .......... .......... 89%  236M 0s\n",
      "214350K .......... .......... .......... .......... .......... 89%  258M 0s\n",
      "214400K .......... .......... .......... .......... .......... 89%  324M 0s\n",
      "214450K .......... .......... .......... .......... .......... 89%  290M 0s\n",
      "214500K .......... .......... .......... .......... .......... 89%  185M 0s\n",
      "214550K .......... .......... .......... .......... .......... 89%  259M 0s\n",
      "214600K .......... .......... .......... .......... .......... 89%  296M 0s\n",
      "214650K .......... .......... .......... .......... .......... 89%  231M 0s\n",
      "214700K .......... .......... .......... .......... .......... 89%  188M 0s\n",
      "214750K .......... .......... .......... .......... .......... 89%  275M 0s\n",
      "214800K .......... .......... .......... .......... .......... 89%  337M 0s\n",
      "214850K .......... .......... .......... .......... .......... 89%  219M 0s\n",
      "214900K .......... .......... .......... .......... .......... 89%  250M 0s\n",
      "214950K .......... .......... .......... .......... .......... 89%  318M 0s\n",
      "215000K .......... .......... .......... .......... .......... 89%  201M 0s\n",
      "215050K .......... .......... .......... .......... .......... 89%  284M 0s\n",
      "215100K .......... .......... .......... .......... .......... 89%  207M 0s\n",
      "215150K .......... .......... .......... .......... .......... 90%  213M 0s\n",
      "215200K .......... .......... .......... .......... .......... 90%  270M 0s\n",
      "215250K .......... .......... .......... .......... .......... 90%  314M 0s\n",
      "215300K .......... .......... .......... .......... .......... 90%  219M 0s\n",
      "215350K .......... .......... .......... .......... .......... 90%  268M 0s\n",
      "215400K .......... .......... .......... .......... .......... 90%  335M 0s\n",
      "215450K .......... .......... .......... .......... .......... 90%  211M 0s\n",
      "215500K .......... .......... .......... .......... .......... 90%  203M 0s\n",
      "215550K .......... .......... .......... .......... .......... 90%  198M 0s\n",
      "215600K .......... .......... .......... .......... .......... 90%  262M 0s\n",
      "215650K .......... .......... .......... .......... .......... 90%  254M 0s\n",
      "215700K .......... .......... .......... .......... .......... 90%  286M 0s\n",
      "215750K .......... .......... .......... .......... .......... 90%  234M 0s\n",
      "215800K .......... .......... .......... .......... .......... 90%  328M 0s\n",
      "215850K .......... .......... .......... .......... .......... 90%  301M 0s\n",
      "215900K .......... .......... .......... .......... .......... 90%  285M 0s\n",
      "215950K .......... .......... .......... .......... .......... 90%  180M 0s\n",
      "216000K .......... .......... .......... .......... .......... 90%  247M 0s\n",
      "216050K .......... .......... .......... .......... .......... 90%  273M 0s\n",
      "216100K .......... .......... .......... .......... .......... 90%  205M 0s\n",
      "216150K .......... .......... .......... .......... .......... 90%  268M 0s\n",
      "216200K .......... .......... .......... .......... .......... 90%  308M 0s\n",
      "216250K .......... .......... .......... .......... .......... 90%  247M 0s\n",
      "216300K .......... .......... .......... .......... .......... 90%  207M 0s\n",
      "216350K .......... .......... .......... .......... .......... 90%  238M 0s\n",
      "216400K .......... .......... .......... .......... .......... 90%  330M 0s\n",
      "216450K .......... .......... .......... .......... .......... 90%  323M 0s\n",
      "216500K .......... .......... .......... .......... .......... 90%  191M 0s\n",
      "216550K .......... .......... .......... .......... .......... 90%  325M 0s\n",
      "216600K .......... .......... .......... .......... .......... 90%  253M 0s\n",
      "216650K .......... .......... .......... .......... .......... 90%  240M 0s\n",
      "216700K .......... .......... .......... .......... .......... 90%  214M 0s\n",
      "216750K .......... .......... .......... .......... .......... 90%  205M 0s\n",
      "216800K .......... .......... .......... .......... .......... 90%  255M 0s\n",
      "216850K .......... .......... .......... .......... .......... 90%  307M 0s\n",
      "216900K .......... .......... .......... .......... .......... 90%  241M 0s\n",
      "216950K .......... .......... .......... .......... .......... 90%  207M 0s\n",
      "217000K .......... .......... .......... .......... .......... 90%  254M 0s\n",
      "217050K .......... .......... .......... .......... .......... 90%  196M 0s\n",
      "217100K .......... .......... .......... .......... .......... 90%  236M 0s\n",
      "217150K .......... .......... .......... .......... .......... 90%  335M 0s\n",
      "217200K .......... .......... .......... .......... .......... 90%  217M 0s\n",
      "217250K .......... .......... .......... .......... .......... 90%  235M 0s\n",
      "217300K .......... .......... .......... .......... .......... 90%  205M 0s\n",
      "217350K .......... .......... .......... .......... .......... 90%  310M 0s\n",
      "217400K .......... .......... .......... .......... .......... 90%  229M 0s\n",
      "217450K .......... .......... .......... .......... .......... 90%  233M 0s\n",
      "217500K .......... .......... .......... .......... .......... 90%  228M 0s\n",
      "217550K .......... .......... .......... .......... .......... 91%  293M 0s\n",
      "217600K .......... .......... .......... .......... .......... 91%  212M 0s\n",
      "217650K .......... .......... .......... .......... .......... 91%  291M 0s\n",
      "217700K .......... .......... .......... .......... .......... 91%  190M 0s\n",
      "217750K .......... .......... .......... .......... .......... 91%  261M 0s\n",
      "217800K .......... .......... .......... .......... .......... 91%  215M 0s\n",
      "217850K .......... .......... .......... .......... .......... 91%  204M 0s\n",
      "217900K .......... .......... .......... .......... .......... 91%  242M 0s\n",
      "217950K .......... .......... .......... .......... .......... 91%  242M 0s\n",
      "218000K .......... .......... .......... .......... .......... 91%  237M 0s\n",
      "218050K .......... .......... .......... .......... .......... 91%  298M 0s\n",
      "218100K .......... .......... .......... .......... .......... 91%  184M 0s\n",
      "218150K .......... .......... .......... .......... .......... 91%  253M 0s\n",
      "218200K .......... .......... .......... .......... .......... 91%  259M 0s\n",
      "218250K .......... .......... .......... .......... .......... 91%  196M 0s\n",
      "218300K .......... .......... .......... .......... .......... 91%  201M 0s\n",
      "218350K .......... .......... .......... .......... .......... 91%  244M 0s\n",
      "218400K .......... .......... .......... .......... .......... 91%  272M 0s\n",
      "218450K .......... .......... .......... .......... .......... 91%  269M 0s\n",
      "218500K .......... .......... .......... .......... .......... 91%  171M 0s\n",
      "218550K .......... .......... .......... .......... .......... 91%  234M 0s\n",
      "218600K .......... .......... .......... .......... .......... 91%  246M 0s\n",
      "218650K .......... .......... .......... .......... .......... 91%  221M 0s\n",
      "218700K .......... .......... .......... .......... .......... 91%  213M 0s\n",
      "218750K .......... .......... .......... .......... .......... 91%  333M 0s\n",
      "218800K .......... .......... .......... .......... .......... 91%  325M 0s\n",
      "218850K .......... .......... .......... .......... .......... 91%  305M 0s\n",
      "218900K .......... .......... .......... .......... .......... 91%  206M 0s\n",
      "218950K .......... .......... .......... .......... .......... 91%  223M 0s\n",
      "219000K .......... .......... .......... .......... .......... 91%  232M 0s\n",
      "219050K .......... .......... .......... .......... .......... 91%  330M 0s\n",
      "219100K .......... .......... .......... .......... .......... 91%  233M 0s\n",
      "219150K .......... .......... .......... .......... .......... 91%  204M 0s\n",
      "219200K .......... .......... .......... .......... .......... 91%  284M 0s\n",
      "219250K .......... .......... .......... .......... .......... 91%  327M 0s\n",
      "219300K .......... .......... .......... .......... .......... 91%  256M 0s\n",
      "219350K .......... .......... .......... .......... .......... 91%  334M 0s\n",
      "219400K .......... .......... .......... .......... .......... 91%  182M 0s\n",
      "219450K .......... .......... .......... .......... .......... 91%  254M 0s\n",
      "219500K .......... .......... .......... .......... .......... 91%  224M 0s\n",
      "219550K .......... .......... .......... .......... .......... 91%  286M 0s\n",
      "219600K .......... .......... .......... .......... .......... 91%  294M 0s\n",
      "219650K .......... .......... .......... .......... .......... 91%  224M 0s\n",
      "219700K .......... .......... .......... .......... .......... 91%  201M 0s\n",
      "219750K .......... .......... .......... .......... .......... 91%  294M 0s\n",
      "219800K .......... .......... .......... .......... .......... 91%  328M 0s\n",
      "219850K .......... .......... .......... .......... .......... 91%  208M 0s\n",
      "219900K .......... .......... .......... .......... .......... 91%  258M 0s\n",
      "219950K .......... .......... .......... .......... .......... 92%  258M 0s\n",
      "220000K .......... .......... .......... .......... .......... 92%  322M 0s\n",
      "220050K .......... .......... .......... .......... .......... 92%  255M 0s\n",
      "220100K .......... .......... .......... .......... .......... 92%  219M 0s\n",
      "220150K .......... .......... .......... .......... .......... 92%  245M 0s\n",
      "220200K .......... .......... .......... .......... .......... 92%  328M 0s\n",
      "220250K .......... .......... .......... .......... .......... 92%  212M 0s\n",
      "220300K .......... .......... .......... .......... .......... 92%  226M 0s\n",
      "220350K .......... .......... .......... .......... .......... 92%  283M 0s\n",
      "220400K .......... .......... .......... .......... .......... 92%  320M 0s\n",
      "220450K .......... .......... .......... .......... .......... 92%  203M 0s\n",
      "220500K .......... .......... .......... .......... .......... 92%  225M 0s\n",
      "220550K .......... .......... .......... .......... .......... 92%  286M 0s\n",
      "220600K .......... .......... .......... .......... .......... 92%  301M 0s\n",
      "220650K .......... .......... .......... .......... .......... 92%  235M 0s\n",
      "220700K .......... .......... .......... .......... .......... 92%  209M 0s\n",
      "220750K .......... .......... .......... .......... .......... 92%  245M 0s\n",
      "220800K .......... .......... .......... .......... .......... 92%  314M 0s\n",
      "220850K .......... .......... .......... .......... .......... 92%  244M 0s\n",
      "220900K .......... .......... .......... .......... .......... 92%  269M 0s\n",
      "220950K .......... .......... .......... .......... .......... 92%  289M 0s\n",
      "221000K .......... .......... .......... .......... .......... 92%  325M 0s\n",
      "221050K .......... .......... .......... .......... .......... 92%  224M 0s\n",
      "221100K .......... .......... .......... .......... .......... 92%  206M 0s\n",
      "221150K .......... .......... .......... .......... .......... 92%  191M 0s\n",
      "221200K .......... .......... .......... .......... .......... 92%  237M 0s\n",
      "221250K .......... .......... .......... .......... .......... 92%  243M 0s\n",
      "221300K .......... .......... .......... .......... .......... 92%  280M 0s\n",
      "221350K .......... .......... .......... .......... .......... 92%  224M 0s\n",
      "221400K .......... .......... .......... .......... .......... 92%  268M 0s\n",
      "221450K .......... .......... .......... .......... .......... 92%  267M 0s\n",
      "221500K .......... .......... .......... .......... .......... 92%  283M 0s\n",
      "221550K .......... .......... .......... .......... .......... 92%  273M 0s\n",
      "221600K .......... .......... .......... .......... .......... 92%  213M 0s\n",
      "221650K .......... .......... .......... .......... .......... 92%  224M 0s\n",
      "221700K .......... .......... .......... .......... .......... 92%  190M 0s\n",
      "221750K .......... .......... .......... .......... .......... 92%  324M 0s\n",
      "221800K .......... .......... .......... .......... .......... 92%  248M 0s\n",
      "221850K .......... .......... .......... .......... .......... 92%  248M 0s\n",
      "221900K .......... .......... .......... .......... .......... 92%  208M 0s\n",
      "221950K .......... .......... .......... .......... .......... 92%  328M 0s\n",
      "222000K .......... .......... .......... .......... .......... 92%  268M 0s\n",
      "222050K .......... .......... .......... .......... .......... 92%  261M 0s\n",
      "222100K .......... .......... .......... .......... .......... 92%  200M 0s\n",
      "222150K .......... .......... .......... .......... .......... 92%  261M 0s\n",
      "222200K .......... .......... .......... .......... .......... 92%  307M 0s\n",
      "222250K .......... .......... .......... .......... .......... 92%  266M 0s\n",
      "222300K .......... .......... .......... .......... .......... 93%  200M 0s\n",
      "222350K .......... .......... .......... .......... .......... 93%  322M 0s\n",
      "222400K .......... .......... .......... .......... .......... 93%  326M 0s\n",
      "222450K .......... .......... .......... .......... .......... 93%  262M 0s\n",
      "222500K .......... .......... .......... .......... .......... 93%  234M 0s\n",
      "222550K .......... .......... .......... .......... .......... 93%  324M 0s\n",
      "222600K .......... .......... .......... .......... .......... 93%  214M 0s\n",
      "222650K .......... .......... .......... .......... .......... 93%  255M 0s\n",
      "222700K .......... .......... .......... .......... .......... 93%  231M 0s\n",
      "222750K .......... .......... .......... .......... .......... 93%  331M 0s\n",
      "222800K .......... .......... .......... .......... .......... 93%  199M 0s\n",
      "222850K .......... .......... .......... .......... .......... 93%  281M 0s\n",
      "222900K .......... .......... .......... .......... .......... 93%  192M 0s\n",
      "222950K .......... .......... .......... .......... .......... 93%  263M 0s\n",
      "223000K .......... .......... .......... .......... .......... 93%  327M 0s\n",
      "223050K .......... .......... .......... .......... .......... 93%  236M 0s\n",
      "223100K .......... .......... .......... .......... .......... 93%  228M 0s\n",
      "223150K .......... .......... .......... .......... .......... 93%  233M 0s\n",
      "223200K .......... .......... .......... .......... .......... 93%  325M 0s\n",
      "223250K .......... .......... .......... .......... .......... 93%  210M 0s\n",
      "223300K .......... .......... .......... .......... .......... 93%  272M 0s\n",
      "223350K .......... .......... .......... .......... .......... 93%  288M 0s\n",
      "223400K .......... .......... .......... .......... .......... 93%  208M 0s\n",
      "223450K .......... .......... .......... .......... .......... 93%  222M 0s\n",
      "223500K .......... .......... .......... .......... .......... 93%  217M 0s\n",
      "223550K .......... .......... .......... .......... .......... 93%  314M 0s\n",
      "223600K .......... .......... .......... .......... .......... 93%  242M 0s\n",
      "223650K .......... .......... .......... .......... .......... 93%  258M 0s\n",
      "223700K .......... .......... .......... .......... .......... 93%  209M 0s\n",
      "223750K .......... .......... .......... .......... .......... 93%  331M 0s\n",
      "223800K .......... .......... .......... .......... .......... 93%  303M 0s\n",
      "223850K .......... .......... .......... .......... .......... 93%  300M 0s\n",
      "223900K .......... .......... .......... .......... .......... 93%  173M 0s\n",
      "223950K .......... .......... .......... .......... .......... 93%  235M 0s\n",
      "224000K .......... .......... .......... .......... .......... 93%  228M 0s\n",
      "224050K .......... .......... .......... .......... .......... 93%  249M 0s\n",
      "224100K .......... .......... .......... .......... .......... 93%  205M 0s\n",
      "224150K .......... .......... .......... .......... .......... 93%  324M 0s\n",
      "224200K .......... .......... .......... .......... .......... 93%  257M 0s\n",
      "224250K .......... .......... .......... .......... .......... 93%  266M 0s\n",
      "224300K .......... .......... .......... .......... .......... 93%  193M 0s\n",
      "224350K .......... .......... .......... .......... .......... 93%  325M 0s\n",
      "224400K .......... .......... .......... .......... .......... 93%  226M 0s\n",
      "224450K .......... .......... .......... .......... .......... 93%  222M 0s\n",
      "224500K .......... .......... .......... .......... .......... 93%  210M 0s\n",
      "224550K .......... .......... .......... .......... .......... 93%  240M 0s\n",
      "224600K .......... .......... .......... .......... .......... 93%  329M 0s\n",
      "224650K .......... .......... .......... .......... .......... 93%  264M 0s\n",
      "224700K .......... .......... .......... .......... .......... 94%  189M 0s\n",
      "224750K .......... .......... .......... .......... .......... 94%  261M 0s\n",
      "224800K .......... .......... .......... .......... .......... 94%  252M 0s\n",
      "224850K .......... .......... .......... .......... .......... 94%  324M 0s\n",
      "224900K .......... .......... .......... .......... .......... 94%  194M 0s\n",
      "224950K .......... .......... .......... .......... .......... 94%  264M 0s\n",
      "225000K .......... .......... .......... .......... .......... 94%  254M 0s\n",
      "225050K .......... .......... .......... .......... .......... 94%  324M 0s\n",
      "225100K .......... .......... .......... .......... .......... 94%  212M 0s\n",
      "225150K .......... .......... .......... .......... .......... 94%  277M 0s\n",
      "225200K .......... .......... .......... .......... .......... 94%  332M 0s\n",
      "225250K .......... .......... .......... .......... .......... 94%  237M 0s\n",
      "225300K .......... .......... .......... .......... .......... 94%  227M 0s\n",
      "225350K .......... .......... .......... .......... .......... 94%  231M 0s\n",
      "225400K .......... .......... .......... .......... .......... 94%  269M 0s\n",
      "225450K .......... .......... .......... .......... .......... 94%  320M 0s\n",
      "225500K .......... .......... .......... .......... .......... 94%  221M 0s\n",
      "225550K .......... .......... .......... .......... .......... 94%  225M 0s\n",
      "225600K .......... .......... .......... .......... .......... 94%  259M 0s\n",
      "225650K .......... .......... .......... .......... .......... 94%  318M 0s\n",
      "225700K .......... .......... .......... .......... .......... 94%  180M 0s\n",
      "225750K .......... .......... .......... .......... .......... 94%  247M 0s\n",
      "225800K .......... .......... .......... .......... .......... 94%  252M 0s\n",
      "225850K .......... .......... .......... .......... .......... 94%  242M 0s\n",
      "225900K .......... .......... .......... .......... .......... 94%  265M 0s\n",
      "225950K .......... .......... .......... .......... .......... 94%  330M 0s\n",
      "226000K .......... .......... .......... .......... .......... 94%  275M 0s\n",
      "226050K .......... .......... .......... .......... .......... 94%  316M 0s\n",
      "226100K .......... .......... .......... .......... .......... 94%  191M 0s\n",
      "226150K .......... .......... .......... .......... .......... 94%  277M 0s\n",
      "226200K .......... .......... .......... .......... .......... 94%  270M 0s\n",
      "226250K .......... .......... .......... .......... .......... 94%  320M 0s\n",
      "226300K .......... .......... .......... .......... .......... 94%  172M 0s\n",
      "226350K .......... .......... .......... .......... .......... 94%  239M 0s\n",
      "226400K .......... .......... .......... .......... .......... 94%  292M 0s\n",
      "226450K .......... .......... .......... .......... .......... 94%  310M 0s\n",
      "226500K .......... .......... .......... .......... .......... 94%  195M 0s\n",
      "226550K .......... .......... .......... .......... .......... 94%  227M 0s\n",
      "226600K .......... .......... .......... .......... .......... 94%  264M 0s\n",
      "226650K .......... .......... .......... .......... .......... 94%  324M 0s\n",
      "226700K .......... .......... .......... .......... .......... 94%  211M 0s\n",
      "226750K .......... .......... .......... .......... .......... 94%  189M 0s\n",
      "226800K .......... .......... .......... .......... .......... 94%  242M 0s\n",
      "226850K .......... .......... .......... .......... .......... 94%  279M 0s\n",
      "226900K .......... .......... .......... .......... .......... 94%  277M 0s\n",
      "226950K .......... .......... .......... .......... .......... 94%  234M 0s\n",
      "227000K .......... .......... .......... .......... .......... 94%  210M 0s\n",
      "227050K .......... .......... .......... .......... .......... 94%  295M 0s\n",
      "227100K .......... .......... .......... .......... .......... 95%  281M 0s\n",
      "227150K .......... .......... .......... .......... .......... 95%  219M 0s\n",
      "227200K .......... .......... .......... .......... .......... 95%  236M 0s\n",
      "227250K .......... .......... .......... .......... .......... 95%  247M 0s\n",
      "227300K .......... .......... .......... .......... .......... 95%  256M 0s\n",
      "227350K .......... .......... .......... .......... .......... 95%  253M 0s\n",
      "227400K .......... .......... .......... .......... .......... 95%  201M 0s\n",
      "227450K .......... .......... .......... .......... .......... 95%  291M 0s\n",
      "227500K .......... .......... .......... .......... .......... 95%  222M 0s\n",
      "227550K .......... .......... .......... .......... .......... 95%  326M 0s\n",
      "227600K .......... .......... .......... .......... .......... 95%  265M 0s\n",
      "227650K .......... .......... .......... .......... .......... 95%  224M 0s\n",
      "227700K .......... .......... .......... .......... .......... 95%  234M 0s\n",
      "227750K .......... .......... .......... .......... .......... 95%  298M 0s\n",
      "227800K .......... .......... .......... .......... .......... 95%  251M 0s\n",
      "227850K .......... .......... .......... .......... .......... 95%  274M 0s\n",
      "227900K .......... .......... .......... .......... .......... 95%  288M 0s\n",
      "227950K .......... .......... .......... .......... .......... 95%  215M 0s\n",
      "228000K .......... .......... .......... .......... .......... 95%  270M 0s\n",
      "228050K .......... .......... .......... .......... .......... 95%  263M 0s\n",
      "228100K .......... .......... .......... .......... .......... 95%  273M 0s\n",
      "228150K .......... .......... .......... .......... .......... 95%  206M 0s\n",
      "228200K .......... .......... .......... .......... .......... 95%  311M 0s\n",
      "228250K .......... .......... .......... .......... .......... 95%  238M 0s\n",
      "228300K .......... .......... .......... .......... .......... 95%  281M 0s\n",
      "228350K .......... .......... .......... .......... .......... 95%  241M 0s\n",
      "228400K .......... .......... .......... .......... .......... 95%  217M 0s\n",
      "228450K .......... .......... .......... .......... .......... 95%  282M 0s\n",
      "228500K .......... .......... .......... .......... .......... 95%  273M 0s\n",
      "228550K .......... .......... .......... .......... .......... 95%  243M 0s\n",
      "228600K .......... .......... .......... .......... .......... 95%  231M 0s\n",
      "228650K .......... .......... .......... .......... .......... 95%  321M 0s\n",
      "228700K .......... .......... .......... .......... .......... 95%  250M 0s\n",
      "228750K .......... .......... .......... .......... .......... 95%  216M 0s\n",
      "228800K .......... .......... .......... .......... .......... 95%  229M 0s\n",
      "228850K .......... .......... .......... .......... .......... 95%  252M 0s\n",
      "228900K .......... .......... .......... .......... .......... 95%  263M 0s\n",
      "228950K .......... .......... .......... .......... .......... 95%  248M 0s\n",
      "229000K .......... .......... .......... .......... .......... 95%  245M 0s\n",
      "229050K .......... .......... .......... .......... .......... 95%  243M 0s\n",
      "229100K .......... .......... .......... .......... .......... 95%  281M 0s\n",
      "229150K .......... .......... .......... .......... .......... 95%  242M 0s\n",
      "229200K .......... .......... .......... .......... .......... 95%  235M 0s\n",
      "229250K .......... .......... .......... .......... .......... 95%  251M 0s\n",
      "229300K .......... .......... .......... .......... .......... 95%  283M 0s\n",
      "229350K .......... .......... .......... .......... .......... 95%  231M 0s\n",
      "229400K .......... .......... .......... .......... .......... 95%  235M 0s\n",
      "229450K .......... .......... .......... .......... .......... 95%  222M 0s\n",
      "229500K .......... .......... .......... .......... .......... 96%  208M 0s\n",
      "229550K .......... .......... .......... .......... .......... 96%  332M 0s\n",
      "229600K .......... .......... .......... .......... .......... 96%  291M 0s\n",
      "229650K .......... .......... .......... .......... .......... 96%  213M 0s\n",
      "229700K .......... .......... .......... .......... .......... 96%  197M 0s\n",
      "229750K .......... .......... .......... .......... .......... 96%  248M 0s\n",
      "229800K .......... .......... .......... .......... .......... 96%  292M 0s\n",
      "229850K .......... .......... .......... .......... .......... 96%  253M 0s\n",
      "229900K .......... .......... .......... .......... .......... 96%  210M 0s\n",
      "229950K .......... .......... .......... .......... .......... 96%  264M 0s\n",
      "230000K .......... .......... .......... .......... .......... 96%  326M 0s\n",
      "230050K .......... .......... .......... .......... .......... 96%  242M 0s\n",
      "230100K .......... .......... .......... .......... .......... 96%  201M 0s\n",
      "230150K .......... .......... .......... .......... .......... 96%  260M 0s\n",
      "230200K .......... .......... .......... .......... .......... 96%  326M 0s\n",
      "230250K .......... .......... .......... .......... .......... 96%  253M 0s\n",
      "230300K .......... .......... .......... .......... .......... 96%  205M 0s\n",
      "230350K .......... .......... .......... .......... .......... 96%  246M 0s\n",
      "230400K .......... .......... .......... .......... .......... 96%  331M 0s\n",
      "230450K .......... .......... .......... .......... .......... 96%  263M 0s\n",
      "230500K .......... .......... .......... .......... .......... 96%  207M 0s\n",
      "230550K .......... .......... .......... .......... .......... 96%  255M 0s\n",
      "230600K .......... .......... .......... .......... .......... 96%  255M 0s\n",
      "230650K .......... .......... .......... .......... .......... 96%  329M 0s\n",
      "230700K .......... .......... .......... .......... .......... 96%  212M 0s\n",
      "230750K .......... .......... .......... .......... .......... 96%  255M 0s\n",
      "230800K .......... .......... .......... .......... .......... 96%  325M 0s\n",
      "230850K .......... .......... .......... .......... .......... 96%  297M 0s\n",
      "230900K .......... .......... .......... .......... .......... 96%  283M 0s\n",
      "230950K .......... .......... .......... .......... .......... 96%  327M 0s\n",
      "231000K .......... .......... .......... .......... .......... 96%  295M 0s\n",
      "231050K .......... .......... .......... .......... .......... 96%  197M 0s\n",
      "231100K .......... .......... .......... .......... .......... 96%  199M 0s\n",
      "231150K .......... .......... .......... .......... .......... 96%  313M 0s\n",
      "231200K .......... .......... .......... .......... .......... 96%  253M 0s\n",
      "231250K .......... .......... .......... .......... .......... 96%  233M 0s\n",
      "231300K .......... .......... .......... .......... .......... 96%  281M 0s\n",
      "231350K .......... .......... .......... .......... .......... 96%  327M 0s\n",
      "231400K .......... .......... .......... .......... .......... 96%  279M 0s\n",
      "231450K .......... .......... .......... .......... .......... 96%  294M 0s\n",
      "231500K .......... .......... .......... .......... .......... 96%  187M 0s\n",
      "231550K .......... .......... .......... .......... .......... 96%  217M 0s\n",
      "231600K .......... .......... .......... .......... .......... 96%  234M 0s\n",
      "231650K .......... .......... .......... .......... .......... 96%  218M 0s\n",
      "231700K .......... .......... .......... .......... .......... 96%  223M 0s\n",
      "231750K .......... .......... .......... .......... .......... 96%  321M 0s\n",
      "231800K .......... .......... .......... .......... .......... 96%  296M 0s\n",
      "231850K .......... .......... .......... .......... .......... 96%  319M 0s\n",
      "231900K .......... .......... .......... .......... .......... 97%  156M 0s\n",
      "231950K .......... .......... .......... .......... .......... 97%  268M 0s\n",
      "232000K .......... .......... .......... .......... .......... 97%  217M 0s\n",
      "232050K .......... .......... .......... .......... .......... 97%  244M 0s\n",
      "232100K .......... .......... .......... .......... .......... 97%  226M 0s\n",
      "232150K .......... .......... .......... .......... .......... 97%  318M 0s\n",
      "232200K .......... .......... .......... .......... .......... 97%  265M 0s\n",
      "232250K .......... .......... .......... .......... .......... 97%  276M 0s\n",
      "232300K .......... .......... .......... .......... .......... 97%  269M 0s\n",
      "232350K .......... .......... .......... .......... .......... 97%  207M 0s\n",
      "232400K .......... .......... .......... .......... .......... 97%  237M 0s\n",
      "232450K .......... .......... .......... .......... .......... 97%  233M 0s\n",
      "232500K .......... .......... .......... .......... .......... 97%  189M 0s\n",
      "232550K .......... .......... .......... .......... .......... 97%  259M 0s\n",
      "232600K .......... .......... .......... .......... .......... 97%  324M 0s\n",
      "232650K .......... .......... .......... .......... .......... 97%  253M 0s\n",
      "232700K .......... .......... .......... .......... .......... 97%  207M 0s\n",
      "232750K .......... .......... .......... .......... .......... 97%  254M 0s\n",
      "232800K .......... .......... .......... .......... .......... 97%  333M 0s\n",
      "232850K .......... .......... .......... .......... .......... 97%  205M 0s\n",
      "232900K .......... .......... .......... .......... .......... 97%  253M 0s\n",
      "232950K .......... .......... .......... .......... .......... 97%  284M 0s\n",
      "233000K .......... .......... .......... .......... .......... 97%  326M 0s\n",
      "233050K .......... .......... .......... .......... .......... 97%  226M 0s\n",
      "233100K .......... .......... .......... .......... .......... 97%  208M 0s\n",
      "233150K .......... .......... .......... .......... .......... 97%  265M 0s\n",
      "233200K .......... .......... .......... .......... .......... 97%  305M 0s\n",
      "233250K .......... .......... .......... .......... .......... 97%  263M 0s\n",
      "233300K .......... .......... .......... .......... .......... 97%  178M 0s\n",
      "233350K .......... .......... .......... .......... .......... 97%  278M 0s\n",
      "233400K .......... .......... .......... .......... .......... 97%  285M 0s\n",
      "233450K .......... .......... .......... .......... .......... 97%  299M 0s\n",
      "233500K .......... .......... .......... .......... .......... 97%  224M 0s\n",
      "233550K .......... .......... .......... .......... .......... 97%  239M 0s\n",
      "233600K .......... .......... .......... .......... .......... 97%  266M 0s\n",
      "233650K .......... .......... .......... .......... .......... 97%  326M 0s\n",
      "233700K .......... .......... .......... .......... .......... 97%  195M 0s\n",
      "233750K .......... .......... .......... .......... .......... 97%  242M 0s\n",
      "233800K .......... .......... .......... .......... .......... 97%  253M 0s\n",
      "233850K .......... .......... .......... .......... .......... 97%  324M 0s\n",
      "233900K .......... .......... .......... .......... .......... 97%  207M 0s\n",
      "233950K .......... .......... .......... .......... .......... 97%  225M 0s\n",
      "234000K .......... .......... .......... .......... .......... 97%  264M 0s\n",
      "234050K .......... .......... .......... .......... .......... 97%  325M 0s\n",
      "234100K .......... .......... .......... .......... .......... 97%  255M 0s\n",
      "234150K .......... .......... .......... .......... .......... 97%  209M 0s\n",
      "234200K .......... .......... .......... .......... .......... 97%  327M 0s\n",
      "234250K .......... .......... .......... .......... .......... 98%  237M 0s\n",
      "234300K .......... .......... .......... .......... .......... 98%  220M 0s\n",
      "234350K .......... .......... .......... .......... .......... 98%  227M 0s\n",
      "234400K .......... .......... .......... .......... .......... 98%  307M 0s\n",
      "234450K .......... .......... .......... .......... .......... 98%  285M 0s\n",
      "234500K .......... .......... .......... .......... .......... 98%  219M 0s\n",
      "234550K .......... .......... .......... .......... .......... 98%  217M 0s\n",
      "234600K .......... .......... .......... .......... .......... 98%  186M 0s\n",
      "234650K .......... .......... .......... .......... .......... 98%  197M 0s\n",
      "234700K .......... .......... .......... .......... .......... 98%  195M 0s\n",
      "234750K .......... .......... .......... .......... .......... 98%  189M 0s\n",
      "234800K .......... .......... .......... .......... .......... 98%  217M 0s\n",
      "234850K .......... .......... .......... .......... .......... 98%  209M 0s\n",
      "234900K .......... .......... .......... .......... .......... 98%  174M 0s\n",
      "234950K .......... .......... .......... .......... .......... 98%  198M 0s\n",
      "235000K .......... .......... .......... .......... .......... 98%  256M 0s\n",
      "235050K .......... .......... .......... .......... .......... 98%  258M 0s\n",
      "235100K .......... .......... .......... .......... .......... 98%  176M 0s\n",
      "235150K .......... .......... .......... .......... .......... 98%  193M 0s\n",
      "235200K .......... .......... .......... .......... .......... 98%  248M 0s\n",
      "235250K .......... .......... .......... .......... .......... 98%  191M 0s\n",
      "235300K .......... .......... .......... .......... .......... 98%  194M 0s\n",
      "235350K .......... .......... .......... .......... .......... 98%  219M 0s\n",
      "235400K .......... .......... .......... .......... .......... 98%  264M 0s\n",
      "235450K .......... .......... .......... .......... .......... 98%  239M 0s\n",
      "235500K .......... .......... .......... .......... .......... 98%  170M 0s\n",
      "235550K .......... .......... .......... .......... .......... 98%  200M 0s\n",
      "235600K .......... .......... .......... .......... .......... 98%  236M 0s\n",
      "235650K .......... .......... .......... .......... .......... 98%  261M 0s\n",
      "235700K .......... .......... .......... .......... .......... 98%  129M 0s\n",
      "235750K .......... .......... .......... .......... .......... 98%  270M 0s\n",
      "235800K .......... .......... .......... .......... .......... 98%  254M 0s\n",
      "235850K .......... .......... .......... .......... .......... 98%  253M 0s\n",
      "235900K .......... .......... .......... .......... .......... 98%  222M 0s\n",
      "235950K .......... .......... .......... .......... .......... 98%  201M 0s\n",
      "236000K .......... .......... .......... .......... .......... 98%  192M 0s\n",
      "236050K .......... .......... .......... .......... .......... 98%  195M 0s\n",
      "236100K .......... .......... .......... .......... .......... 98%  202M 0s\n",
      "236150K .......... .......... .......... .......... .......... 98%  270M 0s\n",
      "236200K .......... .......... .......... .......... .......... 98%  260M 0s\n",
      "236250K .......... .......... .......... .......... .......... 98%  263M 0s\n",
      "236300K .......... .......... .......... .......... .......... 98%  201M 0s\n",
      "236350K .......... .......... .......... .......... .......... 98%  136M 0s\n",
      "236400K .......... .......... .......... .......... .......... 98%  190M 0s\n",
      "236450K .......... .......... .......... .......... .......... 98%  213M 0s\n",
      "236500K .......... .......... .......... .......... .......... 98%  227M 0s\n",
      "236550K .......... .......... .......... .......... .......... 98%  267M 0s\n",
      "236600K .......... .......... .......... .......... .......... 98%  241M 0s\n",
      "236650K .......... .......... .......... .......... .......... 99%  268M 0s\n",
      "236700K .......... .......... .......... .......... .......... 99%  206M 0s\n",
      "236750K .......... .......... .......... .......... .......... 99%  135M 0s\n",
      "236800K .......... .......... .......... .......... .......... 99%  264M 0s\n",
      "236850K .......... .......... .......... .......... .......... 99%  197M 0s\n",
      "236900K .......... .......... .......... .......... .......... 99%  218M 0s\n",
      "236950K .......... .......... .......... .......... .......... 99%  265M 0s\n",
      "237000K .......... .......... .......... .......... .......... 99%  272M 0s\n",
      "237050K .......... .......... .......... .......... .......... 99%  268M 0s\n",
      "237100K .......... .......... .......... .......... .......... 99%  204M 0s\n",
      "237150K .......... .......... .......... .......... .......... 99%  180M 0s\n",
      "237200K .......... .......... .......... .......... .......... 99%  187M 0s\n",
      "237250K .......... .......... .......... .......... .......... 99%  212M 0s\n",
      "237300K .......... .......... .......... .......... .......... 99%  163M 0s\n",
      "237350K .......... .......... .......... .......... .......... 99%  256M 0s\n",
      "237400K .......... .......... .......... .......... .......... 99%  268M 0s\n",
      "237450K .......... .......... .......... .......... .......... 99%  223M 0s\n",
      "237500K .......... .......... .......... .......... .......... 99%  194M 0s\n",
      "237550K .......... .......... .......... .......... .......... 99%  177M 0s\n",
      "237600K .......... .......... .......... .......... .......... 99%  185M 0s\n",
      "237650K .......... .......... .......... .......... .......... 99%  189M 0s\n",
      "237700K .......... .......... .......... .......... .......... 99%  196M 0s\n",
      "237750K .......... .......... .......... .......... .......... 99%  261M 0s\n",
      "237800K .......... .......... .......... .......... .......... 99%  258M 0s\n",
      "237850K .......... .......... .......... .......... .......... 99%  272M 0s\n",
      "237900K .......... .......... .......... .......... .......... 99%  229M 0s\n",
      "237950K .......... .......... .......... .......... .......... 99%  254M 0s\n",
      "238000K .......... .......... .......... .......... .......... 99%  267M 0s\n",
      "238050K .......... .......... .......... .......... .......... 99%  265M 0s\n",
      "238100K .......... .......... .......... .......... .......... 99%  221M 0s\n",
      "238150K .......... .......... .......... .......... .......... 99%  272M 0s\n",
      "238200K .......... .......... .......... .......... .......... 99%  274M 0s\n",
      "238250K .......... .......... .......... .......... .......... 99%  262M 0s\n",
      "238300K .......... .......... .......... .......... .......... 99%  226M 0s\n",
      "238350K .......... .......... .......... .......... .......... 99%  273M 0s\n",
      "238400K .......... .......... .......... .......... .......... 99%  277M 0s\n",
      "238450K .......... .......... .......... .......... .......... 99%  231M 0s\n",
      "238500K .......... .......... .......... .......... .......... 99%  233M 0s\n",
      "238550K .......... .......... .......... .......... .......... 99%  262M 0s\n",
      "238600K .......... .......... .......... .......... .......... 99%  256M 0s\n",
      "238650K .......... .......... .......... .......... .......... 99%  263M 0s\n",
      "238700K .......... .......... .......... .......... .......... 99%  235M 0s\n",
      "238750K .......... .......... .......... .......... .......... 99%  269M 0s\n",
      "238800K .......... .......... .......... .......... .......... 99%  278M 0s\n",
      "238850K .......... .......... .......... .......... .......... 99%  272M 0s\n",
      "238900K .......... .......... .......... .......... .......... 99%  235M 0s\n",
      "238950K .......... .......... .......... .......... .......... 99%  276M 0s\n",
      "239000K .......... .......... .......... .......... .......... 99%  250M 0s\n",
      "239050K .......... .......... .........                       100%  217M=1.2s\n",
      "\n",
      "2025-10-03 01:36:04 (200 MB/s) - ‘/tmp/resnet50.tar.gz’ saved [244817203/244817203]\n",
      "\n",
      "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir /tmp/checkpoint\n",
    "mkdir source_dir/checkpoint\n",
    "wget -O /tmp/resnet50.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz 2>&1 | tail -n 500\n",
    "tar -zxvf /tmp/resnet50.tar.gz --strip-components 2 --directory source_dir/checkpoint ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e04a98",
   "metadata": {},
   "source": [
    "## Edit pipeline.config file\n",
    "\n",
    "The [`pipeline.config`](source_dir/pipeline.config) in the `source_dir` folder should be updated when you experiment with different models. The different config files are available [here](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2).\n",
    "\n",
    ">Note: The provided `pipeline.config` file works well with the `EfficientDet` model. You would need to modify it when working with other models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47483545",
   "metadata": {},
   "source": [
    "## Launch Training Job\n",
    "\n",
    "Now that we have a dataset, a docker image and some pretrained model weights, we can launch the training job. To do so, we create a [Sagemaker Framework](https://sagemaker.readthedocs.io/en/stable/frameworks/index.html), where we indicate the container name, name of the config file, number of training steps etc.\n",
    "\n",
    "The `run_training.sh` script does the following:\n",
    "* train the model for `num_train_steps` \n",
    "* evaluate over the val dataset\n",
    "* export the model\n",
    "\n",
    "Different metrics will be displayed during the evaluation phase, including the mean average precision. These metrics can be used to quantify your model performances and compare over the different iterations.\n",
    "\n",
    "You can also monitor the training progress by navigating to **Training -> Training Jobs** from the Amazon Sagemaker dashboard in the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c7175cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tf2-object-detection-2025-10-03-01-39-20-160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-03 01:39:28 Starting - Starting the training job\n",
      "2025-10-03 01:39:28 Pending - Training job waiting for capacity...\n",
      "2025-10-03 01:39:53 Pending - Preparing the instances for training...\n",
      "2025-10-03 01:40:25 Downloading - Downloading input data...\n",
      "2025-10-03 01:40:40 Downloading - Downloading the training image.........\n",
      "2025-10-03 01:42:31 Training - Training image download completed. Training in progress...\u001b[34m2025-10-03 01:42:42,804 sagemaker-training-toolkit INFO     Provided path: /opt/ml/code  is empty, unzipping\u001b[0m\n",
      "\u001b[34m2025-10-03 01:42:44,968 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-03 01:42:45,005 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-03 01:42:45,042 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-03 01:42:45,055 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/training\",\n",
      "        \"num_train_steps\": \"2000\",\n",
      "        \"pipeline_config_path\": \"pipeline.config\",\n",
      "        \"sample_1_of_n_eval_examples\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"tf2-object-detection-2025-10-03-01-39-20-160\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-738138308218/tf2-object-detection-2025-10-03-01-39-20-160/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_training.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"topology\": null,\n",
      "    \"user_entry_point\": \"run_training.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-738138308218/tf2-object-detection-2025-10-03-01-39-20-160/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"tf2-object-detection-2025-10-03-01-39-20-160\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-738138308218/tf2-object-detection-2025-10-03-01-39-20-160/source/sourcedir.tar.gz\",\"module_name\":\"run_training.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"topology\":null,\"user_entry_point\":\"run_training.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/training\",\"--num_train_steps\",\"2000\",\"--pipeline_config_path\",\"pipeline.config\",\"--sample_1_of_n_eval_examples\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/training\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_STEPS=2000\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_CONFIG_PATH=pipeline.config\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./run_training.sh --model_dir /opt/training --num_train_steps 2000 --pipeline_config_path pipeline.config --sample_1_of_n_eval_examples 1\"\u001b[0m\n",
      "\u001b[34m2025-10-03 01:42:45,056 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m===TRAINING THE MODEL==\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mI1003 01:42:51.592160 140614666106688 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mI1003 01:42:51.868115 140614666106688 config_util.py:552] Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI1003 01:42:51.868256 140614666106688 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mW1003 01:42:51.889631 140614666106688 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1003 01:42:51.895487 140614666106688 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1003 01:42:51.896632 140614666106688 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mI1003 01:42:51.896703 140614666106688 dataset_builder.py:80] Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW1003 01:42:51.902427 140614666106688 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW1003 01:42:51.921314 140614666106688 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW1003 01:42:57.473685 140614666106688 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mW1003 01:42:59.890175 140614666106688 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1003 01:43:01.111906 140614666106688 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI1003 01:43:09.965741 140609055074048 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1003 01:43:17.686287 140609055074048 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.168076 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.170243 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.171017 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.171679 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.174343 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.175024 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.175792 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.176448 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.179105 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1003 01:43:26.179766 140614666106688 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mW1003 01:43:28.170796 140609055074048 deprecation.py:569] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mI1003 01:43:29.185261 140609055074048 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1003 01:43:35.818227 140609055074048 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1003 01:43:41.346616 140609055074048 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1003 01:43:47.457504 140609055074048 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 100 per-step time 0.856s\u001b[0m\n",
      "\u001b[34mI1003 01:44:53.007421 140614666106688 model_lib_v2.py:705] Step 100 per-step time 0.856s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.5018263,\n",
      " 'Loss/localization_loss': 0.5992235,\n",
      " 'Loss/regularization_loss': 0.3924194,\n",
      " 'Loss/total_loss': 1.4934692,\n",
      " 'learning_rate': 0.014666351}\u001b[0m\n",
      "\u001b[34mI1003 01:44:53.007713 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.5018263,\n",
      " 'Loss/localization_loss': 0.5992235,\n",
      " 'Loss/regularization_loss': 0.3924194,\n",
      " 'Loss/total_loss': 1.4934692,\n",
      " 'learning_rate': 0.014666351}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 200 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:45:37.986089 140614666106688 model_lib_v2.py:705] Step 200 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.43739712,\n",
      " 'Loss/localization_loss': 0.58222246,\n",
      " 'Loss/regularization_loss': 0.3910662,\n",
      " 'Loss/total_loss': 1.4106858,\n",
      " 'learning_rate': 0.0159997}\u001b[0m\n",
      "\u001b[34mI1003 01:45:37.986312 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.43739712,\n",
      " 'Loss/localization_loss': 0.58222246,\n",
      " 'Loss/regularization_loss': 0.3910662,\n",
      " 'Loss/total_loss': 1.4106858,\n",
      " 'learning_rate': 0.0159997}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 300 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:46:22.950468 140614666106688 model_lib_v2.py:705] Step 300 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.40500262,\n",
      " 'Loss/localization_loss': 0.530093,\n",
      " 'Loss/regularization_loss': 0.3876688,\n",
      " 'Loss/total_loss': 1.3227644,\n",
      " 'learning_rate': 0.01733305}\u001b[0m\n",
      "\u001b[34mI1003 01:46:22.950692 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.40500262,\n",
      " 'Loss/localization_loss': 0.530093,\n",
      " 'Loss/regularization_loss': 0.3876688,\n",
      " 'Loss/total_loss': 1.3227644,\n",
      " 'learning_rate': 0.01733305}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 400 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:47:07.921163 140614666106688 model_lib_v2.py:705] Step 400 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.36988938,\n",
      " 'Loss/localization_loss': 0.49820337,\n",
      " 'Loss/regularization_loss': 0.3840347,\n",
      " 'Loss/total_loss': 1.2521274,\n",
      " 'learning_rate': 0.0186664}\u001b[0m\n",
      "\u001b[34mI1003 01:47:07.921393 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.36988938,\n",
      " 'Loss/localization_loss': 0.49820337,\n",
      " 'Loss/regularization_loss': 0.3840347,\n",
      " 'Loss/total_loss': 1.2521274,\n",
      " 'learning_rate': 0.0186664}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 500 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:47:52.893435 140614666106688 model_lib_v2.py:705] Step 500 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.34333506,\n",
      " 'Loss/localization_loss': 0.45085278,\n",
      " 'Loss/regularization_loss': 0.3806317,\n",
      " 'Loss/total_loss': 1.1748195,\n",
      " 'learning_rate': 0.01999975}\u001b[0m\n",
      "\u001b[34mI1003 01:47:52.893657 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.34333506,\n",
      " 'Loss/localization_loss': 0.45085278,\n",
      " 'Loss/regularization_loss': 0.3806317,\n",
      " 'Loss/total_loss': 1.1748195,\n",
      " 'learning_rate': 0.01999975}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 600 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:48:37.867401 140614666106688 model_lib_v2.py:705] Step 600 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.34620187,\n",
      " 'Loss/localization_loss': 0.40269154,\n",
      " 'Loss/regularization_loss': 0.3763826,\n",
      " 'Loss/total_loss': 1.1252761,\n",
      " 'learning_rate': 0.0213331}\u001b[0m\n",
      "\u001b[34mI1003 01:48:37.867628 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.34620187,\n",
      " 'Loss/localization_loss': 0.40269154,\n",
      " 'Loss/regularization_loss': 0.3763826,\n",
      " 'Loss/total_loss': 1.1252761,\n",
      " 'learning_rate': 0.0213331}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 700 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:49:22.854583 140614666106688 model_lib_v2.py:705] Step 700 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.27702808,\n",
      " 'Loss/localization_loss': 0.3135368,\n",
      " 'Loss/regularization_loss': 0.37214142,\n",
      " 'Loss/total_loss': 0.9627063,\n",
      " 'learning_rate': 0.02266645}\u001b[0m\n",
      "\u001b[34mI1003 01:49:22.854831 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.27702808,\n",
      " 'Loss/localization_loss': 0.3135368,\n",
      " 'Loss/regularization_loss': 0.37214142,\n",
      " 'Loss/total_loss': 0.9627063,\n",
      " 'learning_rate': 0.02266645}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 800 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:50:07.809923 140614666106688 model_lib_v2.py:705] Step 800 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.3020827,\n",
      " 'Loss/localization_loss': 0.37512892,\n",
      " 'Loss/regularization_loss': 0.36802113,\n",
      " 'Loss/total_loss': 1.0452328,\n",
      " 'learning_rate': 0.023999799}\u001b[0m\n",
      "\u001b[34mI1003 01:50:07.810142 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.3020827,\n",
      " 'Loss/localization_loss': 0.37512892,\n",
      " 'Loss/regularization_loss': 0.36802113,\n",
      " 'Loss/total_loss': 1.0452328,\n",
      " 'learning_rate': 0.023999799}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 900 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:50:52.802411 140614666106688 model_lib_v2.py:705] Step 900 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.30703634,\n",
      " 'Loss/localization_loss': 0.41085187,\n",
      " 'Loss/regularization_loss': 0.36348432,\n",
      " 'Loss/total_loss': 1.0813725,\n",
      " 'learning_rate': 0.025333151}\u001b[0m\n",
      "\u001b[34mI1003 01:50:52.802635 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.30703634,\n",
      " 'Loss/localization_loss': 0.41085187,\n",
      " 'Loss/regularization_loss': 0.36348432,\n",
      " 'Loss/total_loss': 1.0813725,\n",
      " 'learning_rate': 0.025333151}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1000 per-step time 0.449s\u001b[0m\n",
      "\u001b[34mI1003 01:51:37.731051 140614666106688 model_lib_v2.py:705] Step 1000 per-step time 0.449s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.28332105,\n",
      " 'Loss/localization_loss': 0.2648306,\n",
      " 'Loss/regularization_loss': 0.35909513,\n",
      " 'Loss/total_loss': 0.90724677,\n",
      " 'learning_rate': 0.0266665}\u001b[0m\n",
      "\u001b[34mI1003 01:51:37.731266 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.28332105,\n",
      " 'Loss/localization_loss': 0.2648306,\n",
      " 'Loss/regularization_loss': 0.35909513,\n",
      " 'Loss/total_loss': 0.90724677,\n",
      " 'learning_rate': 0.0266665}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1100 per-step time 0.469s\u001b[0m\n",
      "\u001b[34mI1003 01:52:24.627991 140614666106688 model_lib_v2.py:705] Step 1100 per-step time 0.469s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.3006951,\n",
      " 'Loss/localization_loss': 0.33052087,\n",
      " 'Loss/regularization_loss': 0.3549239,\n",
      " 'Loss/total_loss': 0.9861399,\n",
      " 'learning_rate': 0.02799985}\u001b[0m\n",
      "\u001b[34mI1003 01:52:24.628222 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.3006951,\n",
      " 'Loss/localization_loss': 0.33052087,\n",
      " 'Loss/regularization_loss': 0.3549239,\n",
      " 'Loss/total_loss': 0.9861399,\n",
      " 'learning_rate': 0.02799985}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1200 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:53:09.640463 140614666106688 model_lib_v2.py:705] Step 1200 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.32147297,\n",
      " 'Loss/localization_loss': 0.4272268,\n",
      " 'Loss/regularization_loss': 0.35076147,\n",
      " 'Loss/total_loss': 1.0994612,\n",
      " 'learning_rate': 0.0293332}\u001b[0m\n",
      "\u001b[34mI1003 01:53:09.640677 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.32147297,\n",
      " 'Loss/localization_loss': 0.4272268,\n",
      " 'Loss/regularization_loss': 0.35076147,\n",
      " 'Loss/total_loss': 1.0994612,\n",
      " 'learning_rate': 0.0293332}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1300 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:53:54.590779 140614666106688 model_lib_v2.py:705] Step 1300 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.31367254,\n",
      " 'Loss/localization_loss': 0.5135432,\n",
      " 'Loss/regularization_loss': 0.3470251,\n",
      " 'Loss/total_loss': 1.1742408,\n",
      " 'learning_rate': 0.03066655}\u001b[0m\n",
      "\u001b[34mI1003 01:53:54.590993 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.31367254,\n",
      " 'Loss/localization_loss': 0.5135432,\n",
      " 'Loss/regularization_loss': 0.3470251,\n",
      " 'Loss/total_loss': 1.1742408,\n",
      " 'learning_rate': 0.03066655}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1400 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:54:39.586714 140614666106688 model_lib_v2.py:705] Step 1400 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24109694,\n",
      " 'Loss/localization_loss': 0.27951327,\n",
      " 'Loss/regularization_loss': 0.34195933,\n",
      " 'Loss/total_loss': 0.8625696,\n",
      " 'learning_rate': 0.0319999}\u001b[0m\n",
      "\u001b[34mI1003 01:54:39.587399 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.24109694,\n",
      " 'Loss/localization_loss': 0.27951327,\n",
      " 'Loss/regularization_loss': 0.34195933,\n",
      " 'Loss/total_loss': 0.8625696,\n",
      " 'learning_rate': 0.0319999}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1500 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:55:24.594135 140614666106688 model_lib_v2.py:705] Step 1500 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.20512466,\n",
      " 'Loss/localization_loss': 0.21290275,\n",
      " 'Loss/regularization_loss': 0.33689252,\n",
      " 'Loss/total_loss': 0.7549199,\n",
      " 'learning_rate': 0.03333325}\u001b[0m\n",
      "\u001b[34mI1003 01:55:24.594354 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.20512466,\n",
      " 'Loss/localization_loss': 0.21290275,\n",
      " 'Loss/regularization_loss': 0.33689252,\n",
      " 'Loss/total_loss': 0.7549199,\n",
      " 'learning_rate': 0.03333325}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1600 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:56:09.618224 140614666106688 model_lib_v2.py:705] Step 1600 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.3269521,\n",
      " 'Loss/localization_loss': 0.31184715,\n",
      " 'Loss/regularization_loss': 0.33209476,\n",
      " 'Loss/total_loss': 0.97089404,\n",
      " 'learning_rate': 0.034666598}\u001b[0m\n",
      "\u001b[34mI1003 01:56:09.618441 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.3269521,\n",
      " 'Loss/localization_loss': 0.31184715,\n",
      " 'Loss/regularization_loss': 0.33209476,\n",
      " 'Loss/total_loss': 0.97089404,\n",
      " 'learning_rate': 0.034666598}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1700 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:56:54.613274 140614666106688 model_lib_v2.py:705] Step 1700 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.257857,\n",
      " 'Loss/localization_loss': 0.27039737,\n",
      " 'Loss/regularization_loss': 0.3275052,\n",
      " 'Loss/total_loss': 0.85575956,\n",
      " 'learning_rate': 0.03599995}\u001b[0m\n",
      "\u001b[34mI1003 01:56:54.613500 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.257857,\n",
      " 'Loss/localization_loss': 0.27039737,\n",
      " 'Loss/regularization_loss': 0.3275052,\n",
      " 'Loss/total_loss': 0.85575956,\n",
      " 'learning_rate': 0.03599995}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1800 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:57:39.594878 140614666106688 model_lib_v2.py:705] Step 1800 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.21751454,\n",
      " 'Loss/localization_loss': 0.30056798,\n",
      " 'Loss/regularization_loss': 0.32299834,\n",
      " 'Loss/total_loss': 0.8410809,\n",
      " 'learning_rate': 0.037333302}\u001b[0m\n",
      "\u001b[34mI1003 01:57:39.595093 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.21751454,\n",
      " 'Loss/localization_loss': 0.30056798,\n",
      " 'Loss/regularization_loss': 0.32299834,\n",
      " 'Loss/total_loss': 0.8410809,\n",
      " 'learning_rate': 0.037333302}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1900 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:58:24.551660 140614666106688 model_lib_v2.py:705] Step 1900 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.22090696,\n",
      " 'Loss/localization_loss': 0.31679708,\n",
      " 'Loss/regularization_loss': 0.3185042,\n",
      " 'Loss/total_loss': 0.85620826,\n",
      " 'learning_rate': 0.03866665}\u001b[0m\n",
      "\u001b[34mI1003 01:58:24.551878 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.22090696,\n",
      " 'Loss/localization_loss': 0.31679708,\n",
      " 'Loss/regularization_loss': 0.3185042,\n",
      " 'Loss/total_loss': 0.85620826,\n",
      " 'learning_rate': 0.03866665}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 2000 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mI1003 01:59:09.525157 140614666106688 model_lib_v2.py:705] Step 2000 per-step time 0.450s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.26170036,\n",
      " 'Loss/localization_loss': 0.38388717,\n",
      " 'Loss/regularization_loss': 0.31415147,\n",
      " 'Loss/total_loss': 0.95973897,\n",
      " 'learning_rate': 0.04}\u001b[0m\n",
      "\u001b[34mI1003 01:59:09.525395 140614666106688 model_lib_v2.py:708] {'Loss/classification_loss': 0.26170036,\n",
      " 'Loss/localization_loss': 0.38388717,\n",
      " 'Loss/regularization_loss': 0.31415147,\n",
      " 'Loss/total_loss': 0.95973897,\n",
      " 'learning_rate': 0.04}\u001b[0m\n",
      "\u001b[34m==EVALUATING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mW1003 01:59:17.020310 140195495782208 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mI1003 01:59:17.020467 140195495782208 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI1003 01:59:17.020542 140195495782208 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mI1003 01:59:17.020624 140195495782208 config_util.py:552] Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mW1003 01:59:17.020754 140195495782208 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1003 01:59:17.380696 140195495782208 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1003 01:59:17.381679 140195495782208 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mI1003 01:59:17.381760 140195495782208 dataset_builder.py:80] Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mW1003 01:59:17.381829 140195495782208 dataset_builder.py:86] num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mW1003 01:59:17.383476 140195495782208 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW1003 01:59:17.384829 140195495782208 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW1003 01:59:17.402858 140195495782208 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW1003 01:59:20.793107 140195495782208 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1003 01:59:21.597868 140195495782208 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI1003 01:59:24.094187 140195495782208 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34mI1003 01:59:24.094791 140195495782208 checkpoint_utils.py:177] Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI1003 01:59:29.022423 140195495782208 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1003 01:59:48.465919 140195495782208 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1003 02:00:04.714325 140195495782208 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI1003 02:00:04.754268 140195495782208 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mW1003 02:00:04.869010 140195495782208 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI1003 02:00:20.953251 140195495782208 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI1003 02:00:34.880575 140195495782208 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mI1003 02:00:46.337350 140195495782208 coco_evaluation.py:293] Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI1003 02:00:46.341203 140195495782208 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mI1003 02:00:46.353090 140195495782208 coco_tools.py:138] DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.214823 140195495782208 model_lib_v2.py:1015] Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.040893\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.232676 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.040893\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.074235\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.234087 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.074235\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.040456\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.235015 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.040456\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): 0.011678\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.235939 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): 0.011678\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.142116\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.236805 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.142116\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.336395\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.237762 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.336395\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.011360\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.238662 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.011360\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.051886\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.239603 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.051886\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.076267\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.240467 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.076267\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): 0.030297\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.241468 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): 0.030297\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.297102\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.242391 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.297102\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.488118\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.243340 140195495782208 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.488118\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.506542\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.244071 140195495782208 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.506542\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 0.466865\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.244819 140195495782208 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.466865\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.314107\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.245623 140195495782208 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.314107\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 1.287515\u001b[0m\n",
      "\u001b[34mI1003 02:00:54.246341 140195495782208 model_lib_v2.py:1018] #011+ Loss/total_loss: 1.287515\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI1003 02:04:24.187698 140195495782208 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mI1003 02:04:33.201705 140195495782208 checkpoint_utils.py:231] Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mRunning per image evaluation...\u001b[0m\n",
      "\u001b[34mEvaluate annotation type *bbox*\u001b[0m\n",
      "\u001b[34mDONE (t=7.65s).\u001b[0m\n",
      "\u001b[34mAccumulating evaluation results...\u001b[0m\n",
      "\u001b[34mDONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\u001b[0m\n",
      "\u001b[34m==EXPORTING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mW1003 02:04:38.119635 140415380125504 deprecation.py:641] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mI1003 02:04:41.876367 140415380125504 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1003 02:04:58.845530 140415380125504 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1003 02:05:11.825447 140415380125504 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_classpredictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\u001b[0m\n",
      "\u001b[34mI1003 02:05:13.503704 140415380125504 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb44c362bb0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1003 02:05:24.496580 140415380125504 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fb44c362bb0>, because it is not built.\u001b[0m\n",
      "\u001b[34mI1003 02:05:36.723435 140415380125504 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 278). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI1003 02:06:01.194818 140415380125504 builder_impl.py:804] Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI1003 02:06:11.664904 140415380125504 fingerprinting_utils.py:48] Writing fingerprint to /tmp/exported/saved_model/fingerprint.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34mI1003 02:06:12.198020 140415380125504 config_util.py:253] Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34m2025-10-03 02:06:14,215 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-10-03 02:06:44 Uploading - Uploading generated training model\n",
      "2025-10-03 02:06:44 Completed - Training job completed\n",
      "Training seconds: 1579\n",
      "Billable seconds: 1579\n"
     ]
    }
   ],
   "source": [
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_s3_prefix,\n",
    "    container_local_output_path='/opt/training/'\n",
    ")\n",
    "\n",
    "estimator = CustomFramework(\n",
    "    role=role,\n",
    "    image_uri=container,\n",
    "    entry_point='run_training.sh',\n",
    "    source_dir='source_dir/',\n",
    "    hyperparameters={\n",
    "        \"model_dir\": \"/opt/training\",        \n",
    "        \"pipeline_config_path\": \"pipeline.config\",\n",
    "        \"num_train_steps\": \"2000\",    \n",
    "        \"sample_1_of_n_eval_examples\": \"1\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    disable_profiler=True,\n",
    "    base_job_name='tf2-object-detection'\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84545881",
   "metadata": {},
   "source": [
    "You should be able to see your model training in the AWS webapp as shown below:\n",
    "![ECR Example](../data/example_trainings.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9844f25",
   "metadata": {},
   "source": [
    "## Improve on the initial model\n",
    "\n",
    "Most likely, this initial experiment did not yield optimal results. However, you can make multiple changes to the `pipeline.config` file to improve this model. One obvious change consists in improving the data augmentation strategy. The [`preprocessor.proto`](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) file contains the different data augmentation method available in the Tf Object Detection API. Justify your choices of augmentations in the write-up.\n",
    "\n",
    "Keep in mind that the following are also available:\n",
    "* experiment with the optimizer: type of optimizer, learning rate, scheduler etc\n",
    "* experiment with the architecture. The Tf Object Detection API model zoo offers many architectures. Keep in mind that the pipeline.config file is unique for each architecture and you will have to edit it.\n",
    "* visualize results on the test frames using the `2_deploy_model` notebook available in this repository.\n",
    "\n",
    "In the cell below, write down all the different approaches you have experimented with, why you have chosen them and what you would have done if you had more time and resources. Justify your choices using the tensorboard visualizations (take screenshots and insert them in your write-up), the metrics on the evaluation set and the generated animation you have created with [this tool](../2_run_inference/2_deploy_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17284a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your write-up goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
